{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyPTffTLug7i"
   },
   "source": [
    "# **Laboratorio 11: LLM y Agentes Autónomos 🤖**\n",
    "\n",
    "MDS7202: Laboratorio de Programación Científica para Ciencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pbWVyntzbvL"
   },
   "source": [
    "### **Cuerpo Docente:**\n",
    "\n",
    "- Profesores: Ignacio Meza, Sebastián Tinoco\n",
    "- Auxiliar: Eduardo Moya\n",
    "- Ayudantes: Nicolás Ojeda, Melanie Peña, Valentina Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6ikgVYzghB"
   },
   "source": [
    "### Equipo: **SUPER IMPORTANTE - notebooks sin nombre no serán revisados**\n",
    "\n",
    "- Nombre de alumno 1: Joaquín De Groote\n",
    "- Nombre de alumno 2: Vicente Pinochet R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMJ-owchzjFf"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [Insertar Enlace](https://github.com/Qajirr/MDS7202-Labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUuwsXrKzmkK"
   },
   "source": [
    "## **Temas a tratar**\n",
    "\n",
    "- Reinforcement Learning\n",
    "- Large Language Models\n",
    "\n",
    "## **Reglas:**\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Prohibidas las copias.\n",
    "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
    "\n",
    "### **Objetivos principales del laboratorio**\n",
    "\n",
    "- Resolución de problemas secuenciales usando Reinforcement Learning\n",
    "- Habilitar un Chatbot para entregar respuestas útiles usando Large Language Models.\n",
    "\n",
    "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hmHHQ9BuyAG"
   },
   "source": [
    "## **1. Reinforcement Learning (2.0 puntos)**\n",
    "\n",
    "En esta sección van a usar métodos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOcejYb6uzOO"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq gymnasium stable_baselines3\n",
    "!pip install -qqq swig\n",
    "!pip install -qqq gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBPet_Mq8dX9"
   },
   "source": [
    "### **1.1 Blackjack (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "La idea de esta subsección es que puedan implementar métodos de RL y así generar una estrategia para jugar el clásico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
    "\n",
    "Comencemos primero preparando el ambiente. El siguiente bloque de código transforma las observaciones del ambiente a `np.array`:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</p>\n",
    "\n",
    "La idea de esta subsección es que puedan implementar métodos de RL y así generar una estrategia para jugar el clásico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
    "\n",
    "Comencemos primero preparando el ambiente. El siguiente bloque de código transforma las observaciones del ambiente a `np.array`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpZ8bBKk9ZlU"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import MultiDiscrete\n",
    "import numpy as np\n",
    "\n",
    "class FlattenObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(FlattenObservation, self).__init__(env)\n",
    "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.array(observation).flatten()\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make(\"Blackjack-v1\")\n",
    "env = FlattenObservation(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ6J1_-Y9nHO"
   },
   "source": [
    "#### **1.1.1 Descripción de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripción sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5i1Wt1p770x"
   },
   "source": [
    "`escriba su respuesta acá`\n",
    "\n",
    "**Blackjack - Descripción del Ambiente**\n",
    "\n",
    "El objetivo en **Blackjack** es vencer al dealer obteniendo cartas que sumen lo más cerca posible a 21, sin pasarse. El juego comienza con el dealer mostrando una carta y otra oculta, mientras el jugador recibe dos cartas visibles. Las cartas se sacan de un mazo infinito.\n",
    "\n",
    "**Valores de las cartas**:\n",
    "- Cartas de figuras (J, Q, K): **10 puntos**.\n",
    "- Ases: **1 o 11 puntos** (usable ace).\n",
    "- Cartas numéricas (2-9): Valor numérico.\n",
    "\n",
    "**Acciones**:\n",
    "- **0 (Stick)**: Detenerse.\n",
    "- **1 (Hit)**: Pedir una carta.\n",
    "\n",
    "**Espacio de observación**:\n",
    "- Tupla \\((suma\\_jugador, carta\\_dealer, as\\_usable)\\):\n",
    "  - **suma\\_jugador**: 4-21.\n",
    "  - **carta\\_dealer**: 1-10.\n",
    "  - **as\\_usable**: 0 o 1.\n",
    "\n",
    "**Recompensas**:\n",
    "- **+1**: Victoria.\n",
    "- **0**: Empate.\n",
    "- **-1**: Derrota.\n",
    "- **+1.5**: Blackjack natural (opcional).\n",
    "\n",
    "**Fin del episodio**:\n",
    "- Cuando el jugador se pasa de 21 o elige \"Stick\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmcX6bRC9agQ"
   },
   "source": [
    "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 5000 veces y reporte el promedio y desviación de las recompensas. ¿Cómo calificaría el performance de esta política? ¿Cómo podría interpretar las recompensas obtenidas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p2PrLLR9yju"
   },
   "outputs": [],
   "source": [
    "# Simulación de 5000 episodios con acciones aleatorias\n",
    "num_episodes = 5000\n",
    "rewards = []\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    observation, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        # Tomar una acción aleatoria (0: Stick, 1: Hit)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    rewards.append(total_reward)\n",
    "\n",
    "# Calcular estadísticas\n",
    "mean_reward = np.mean(rewards)\n",
    "std_reward = np.std(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El promedio negativo de recompensas **-0.40** sugiere que la política de tomar acciones aleatorias resulta en más derrotas que victorias. Esto implica que el jugador pierde más de lo que gana en promedio. La desviación estándar de **0.89** muestra una considerable variabilidad en los resultados, lo que indica que las recompensas fluctúan significativamente de un episodio a otro.\n",
    "\n",
    "**Conclusión**: El performance de esta política aleatoria es pobre, ya que genera pérdidas más frecuentemente. Para mejorar, se necesitaría una estrategia que considere la probabilidad de ganar y optimice las acciones en consecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEO_dY4x_SJu"
   },
   "source": [
    "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9JsFA1wGmnH"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "# Crear el modelo DQN\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Entrenar el modelo durante 10000 pasos\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(\"dqn_blackjack_model\")\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "episodes = 1000\n",
    "rewards = []\n",
    "\n",
    "for _ in range(episodes):\n",
    "    observation, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(observation, deterministic=True)\n",
    "        observation, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "    rewards.append(total_reward)\n",
    "\n",
    "mean_reward = np.mean(rewards)\n",
    "print(f\"Recompensa promedio después del entrenamiento: {mean_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-bpdb8wZID1"
   },
   "source": [
    "#### **1.1.4 Evaluación de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-d7d8GFf7F6"
   },
   "outputs": [],
   "source": [
    "model = DQN.load(\"dqn_blackjack_model\")\n",
    "\n",
    "# Evaluar el rendimiento del modelo entrenado\n",
    "episodes = 1000\n",
    "rewards_trained_model = []\n",
    "\n",
    "for _ in range(episodes):\n",
    "    observation, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        # Predecir la acción con el modelo entrenado\n",
    "        action, _ = model.predict(observation, deterministic=True)\n",
    "        observation, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "    rewards_trained_model.append(total_reward)\n",
    "\n",
    "# Calcular las estadísticas para el modelo entrenado\n",
    "mean_reward_trained = np.mean(rewards_trained_model)\n",
    "std_reward_trained = np.std(rewards_trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El promedio negativo de recompensas **-0.06** sugiere que el modelo entrenado aún tiene un rendimiento ligeramente negativo, con un equilibrio entre victorias y derrotas. Esto implica que, aunque el agente ha aprendido a jugar, no genera ganancias consistentes en promedio. La desviación estándar de  **0.96** muestra una considerable variabilidad en los resultados, lo que indica que las recompensas fluctúan significativamente de un episodio a otro.\n",
    "\n",
    "**Conclusión**: El performance del modelo entrenado es mejor que el de la política aleatoria, pero aún no es ideal. Para mejorar, se podría optimizar el modelo, ajustar parámetros o explorar diferentes estrategias de aprendizaje para incrementar la tasa de victorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO-EsAaPAYEm"
   },
   "source": [
    "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
    "\n",
    "Genere una función que reciba un estado y retorne la accion del agente. Luego, use esta función para entregar la acción escogida frente a los siguientes escenarios:\n",
    "\n",
    "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
    "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
    "\n",
    "¿Son coherentes sus acciones con las reglas del juego?\n",
    "\n",
    "Hint: ¿A que clase de python pertenecen los estados? Pruebe a usar el método `.reset` para saberlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = env.reset()\n",
    "\n",
    "# Verificar el tipo del estado\n",
    "print(f\"Tipo de estado: {type(initial_state)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh8XlGyzwtRp"
   },
   "outputs": [],
   "source": [
    "# Función para obtener la acción del agente dada una observación\n",
    "def get_agent_action(state):\n",
    "    action, _ = model.predict(state, deterministic=True)\n",
    "    return action\n",
    "\n",
    "# Escenario 1: Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene un as\n",
    "# Estado: (6, 7, 0)\n",
    "state_1 = np.array([6, 7, 0])\n",
    "\n",
    "# Escenario 2: Suma de cartas del agente es 19, dealer muestra un 3, agente tiene un as\n",
    "# Estado: (19, 3, 1)\n",
    "state_2 = np.array([19, 3, 1])\n",
    "\n",
    "# Obtener las acciones para ambos estados\n",
    "action_1 = get_agent_action(state_1)\n",
    "action_2 = get_agent_action(state_2)\n",
    "\n",
    "# Mostrar las acciones\n",
    "print(f\"Acción para el escenario 1 (estado {state_1}): {'Hit' if action_1 == 1 else 'Stick'}\")\n",
    "print(f\"Acción para el escenario 2 (estado {state_2}): {'Hit' if action_2 == 1 else 'Stick'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escenario 1: La suma de cartas del agente es 6, el dealer muestra un 7 y el agente no tiene un as.\n",
    "\n",
    "- Regla general: Cuando el agente tiene una suma baja, es probable que deba \"hit\" (pedir más cartas) hasta llegar a una suma más cercana a 21.\n",
    "- Esperado: El modelo debería elegir hit.\n",
    "\n",
    "Escenario 2: La suma de cartas del agente es 19, el dealer muestra un 3, y el agente tiene un as.\n",
    "\n",
    "- Regla general: Con una suma alta (como 19), el agente debería plantarse (stick). Tener un as como \"usable ace\" podría hacer que el agente sea un poco más flexible, pero aún así, la estrategia general es plantarse.\n",
    "- Esperado: El modelo debería elegir stick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEqCTqqroh03"
   },
   "source": [
    "### **1.2 LunarLander**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la sección 2.1, en esta sección usted se encargará de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
    "\n",
    "Comencemos preparando el ambiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvQUyuZ_FtZ4"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\", continuous = True) # notar el parámetro continuous = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBU4lGX3wpN6"
   },
   "source": [
    "Noten que se especifica el parámetro `continuous = True`. ¿Que implicancias tiene esto sobre el ambiente?\n",
    "\n",
    "Además, se le facilita la función `export_gif` para el ejercicio 2.2.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRiWpSo9yfr9"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "def export_gif(model, n = 5):\n",
    "  '''\n",
    "  función que exporta a gif el comportamiento del agente en n episodios\n",
    "  '''\n",
    "  images = []\n",
    "  for episode in range(n):\n",
    "    obs = model.env.reset()\n",
    "    img = model.env.render()\n",
    "    done = False\n",
    "    while not done:\n",
    "      images.append(img)\n",
    "      action, _ = model.predict(obs)\n",
    "      obs, reward, done, info = model.env.step(action)\n",
    "      img = model.env.render(mode=\"rgb_array\")\n",
    "\n",
    "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sk5VJVppXh3N"
   },
   "source": [
    "#### **1.2.1 Descripción de MDP (0.2 puntos)**\n",
    "\n",
    "Entregue una breve descripción sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. ¿Como se distinguen las acciones de este ambiente en comparación a `Blackjack`?\n",
    "\n",
    "Nota: recuerde que se especificó el parámetro `continuous = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb-u9LUE8O9a"
   },
   "source": [
    "`escriba su respuesta acá`\n",
    "\n",
    "### **Descripción de MDP en LunarLander-v2**\n",
    "\n",
    "El entorno **LunarLander-v2** simula un problema de optimización de la trayectoria de un cohete, donde el objetivo es aterrizar el módulo en la luna. La formulación en MDP es la siguiente:\n",
    "\n",
    "#### **Estado (S)**\n",
    "El estado es un vector de 8 dimensiones que incluye:\n",
    "- **x, y**: Coordenadas del módulo.\n",
    "- **vx, vy**: Velocidades en los ejes horizontal y vertical.\n",
    "- **ángulo**: Orientación del módulo.\n",
    "- **velocidad angular**: Rotación del módulo.\n",
    "- **contacto con piernas**: Booleanos que indican si las piernas están tocando el suelo.\n",
    "\n",
    "#### **Acciones (A)**\n",
    "Existen 4 acciones posibles:\n",
    "- **0**: No hacer nada.\n",
    "- **1**: Encender el motor izquierdo (orientación).\n",
    "- **2**: Encender el motor principal (vertical).\n",
    "- **3**: Encender el motor derecho (orientación).\n",
    "\n",
    "#### **Recompensas (R)**\n",
    "La recompensa depende de la posición, velocidad, y orientación del módulo:\n",
    "- Posicionarse cerca de la plataforma y reducir la velocidad es premiado.\n",
    "- Se penaliza la inclinación del módulo.\n",
    "- **+10 puntos por pierna** si toca el suelo.\n",
    "- Penalizaciones por el uso de motores: **-0.03** por cada cuadro con motores laterales encendidos, **-0.3** por el motor principal.\n",
    "- **+100 puntos** por aterrizaje seguro, **-100 puntos** por estrellarse.\n",
    "\n",
    "#### **Comparación con Blackjack**\n",
    "A diferencia de **Blackjack**, las acciones en **LunarLander** son físicas, controlando motores para afectar la posición, velocidad y orientación en un entorno 2D. En **Blackjack**, las decisiones son más simples y se basan en probabilidades de cartas. Además, en LunarLander las acciones se manejan de forma discreta pero más compleja.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YChodtNQwzG2"
   },
   "source": [
    "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
    "\n",
    "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 10 veces y reporte el promedio y desviación de las recompensas. ¿Cómo calificaría el performance de esta política?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bwc3A0GX7a8"
   },
   "outputs": [],
   "source": [
    "# Función para ejecutar una política aleatoria y obtener las recompensas\n",
    "def simulate_random_policy(env, episodes=10):\n",
    "    rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action = env.action_space.sample()  # Acción aleatoria\n",
    "            obs, reward, done, _, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "        rewards.append(total_reward)\n",
    "    return rewards\n",
    "\n",
    "# Simulación y cálculo de estadísticas\n",
    "rewards = simulate_random_policy(env, episodes=10)\n",
    "mean_reward = np.mean(rewards)\n",
    "std_reward = np.std(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El promedio negativo de recompensas **-237.81** sugiere que la política aleatoria tiene un rendimiento deficiente, con una tendencia a las pérdidas. Esto implica que, al no optimizar las acciones, el agente pierde más de lo que gana en promedio. La desviación estándar de **108.99** muestra una considerable variabilidad en los resultados, lo que indica que las recompensas fluctúan significativamente de un episodio a otro.\n",
    "\n",
    "**Conclusión**: El performance de esta política aleatoria es pobre y no permite ganar consistentemente. Se necesita una estrategia más optimizada para mejorar el rendimiento en este entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQrZVQflX_5f"
   },
   "source": [
    "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
    "\n",
    "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_6Ia9uoF7Hs"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "# Definir y entrenar el modelo con PPO\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(\"ppo_lunarlander_10000_steps\")\n",
    "\n",
    "# Evaluar el modelo entrenado\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_rewards = 0\n",
    "\n",
    "# Realizar una evaluación para ver cómo se desempeña el modelo\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    total_rewards += reward\n",
    "\n",
    "print(f\"Recompensa total al final del episodio: {total_rewards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3z-oIUSrlAsY"
   },
   "source": [
    "#### **1.2.4 Evaluación de modelo (0.2 puntos)**\n",
    "\n",
    "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ophyU3KrWrwl"
   },
   "outputs": [],
   "source": [
    "# Cargar el modelo entrenado\n",
    "model = PPO.load(\"ppo_lunarlander_10000_steps\",env)\n",
    "\n",
    "# Número de episodios para evaluar\n",
    "num_episodes = 10\n",
    "rewards = []\n",
    "\n",
    "# Evaluación del modelo en varios episodios\n",
    "for _ in range(num_episodes):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    rewards.append(total_reward)\n",
    "\n",
    "# Calcular el promedio y desviación estándar de las recompensas\n",
    "mean_reward_trained = np.mean(rewards)\n",
    "std_reward_trained = np.std(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El promedio de recompensas del modelo entrenado es **-189.59**, lo que sugiere que el modelo tiene un rendimiento moderado, aunque no es perfecto. Esto indica que el agente ha aprendido a optimizar sus acciones, pero aún podría mejorar en algunos aspectos. La desviación estándar de **165.69** muestra que las recompensas fluctúan entre episodios, lo que sugiere cierta variabilidad en el desempeño del agente.\n",
    "\n",
    "**Comparación con la política baseline**: Comparando este rendimiento con la política baseline (acción aleatoria), podemos concluir que el modelo entrenado tiene un rendimiento mucho mejor, ya que la política aleatoria generaba un promedio de **-206.93** recompensas, mientras que el modelo entrenado está significativamente por encima de ese valor.\n",
    "\n",
    "**Conclusión**: El rendimiento del agente entrenado es superior al de la política baseline, pero aún existen oportunidades para mejorar. El agente ha aprendido a jugar, pero su desempeño podría optimizarse con más entrenamiento o ajustes en los hiperparámetros del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6Xw4YHT3P5d"
   },
   "source": [
    "#### **1.2.5 Optimización de modelo (0.2 puntos)**\n",
    "\n",
    "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente parámetros como:\n",
    "- `total_timesteps`\n",
    "- `learning_rate`\n",
    "- `batch_size`\n",
    "\n",
    "Una vez optimizado el modelo, use la función `export_gif` para estudiar el comportamiento de su agente en la resolución del ambiente y comente sobre sus resultados.\n",
    "\n",
    "Adjunte el gif generado en su entrega (mejor aún si además adjuntan el gif en el markdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros para la optimización\n",
    "total_timesteps = 80000\n",
    "learning_rate = 0.0003  # Ajuste del learning rate\n",
    "batch_size = 64  # Aumento del tamaño del batch\n",
    "\n",
    "# Definir y entrenar el modelo con PPO\n",
    "model = PPO(\"MlpPolicy\", env, learning_rate=learning_rate, batch_size=batch_size, verbose=1)\n",
    "model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(\"ppo_lunarlander_opt\")\n",
    "\n",
    "# Evaluar el modelo entrenado\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_rewards = 0\n",
    "\n",
    "# Realizar una evaluación\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, truncated, _ = env.step(action)\n",
    "    total_rewards += reward\n",
    "    \n",
    "    # Si el episodio termina o es truncado, detener\n",
    "    if done or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"Recompensa total al final del episodio: {total_rewards}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aItYF6sr6F_6"
   },
   "outputs": [],
   "source": [
    "# Cargar el modelo entrenado\n",
    "model = PPO.load(\"ppo_lunarlander_opt\",env)\n",
    "\n",
    "# Número de episodios para evaluar\n",
    "num_episodes = 5\n",
    "rewards = []\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # Si el episodio termina o es truncado, detener\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "\n",
    "# Calcular el promedio y desviación estándar de las recompensas\n",
    "mean_reward_trained = np.mean(rewards)\n",
    "std_reward_trained = np.std(rewards)\n",
    "\n",
    "print(f\"Promedio de recompensas: {mean_reward_trained:.2f}\")\n",
    "print(f\"Desviación estándar de recompensas: {std_reward_trained:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un GIF del comportamiento del agente optimizado\n",
    "export_gif(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El promedio de recompensas del modelo optimizado es **67.74**, lo que sugiere que el agente ha mejorado significativamente su desempeño, alcanzando un rendimiento superior a 50 recompensas en promedio. Esto indica que el agente ha aprendido a optimizar sus acciones de manera efectiva. La desviación estándar de **49.35** muestra que las recompensas son más consistentes que antes, lo que refleja una mejora en la estabilidad del agente.\n",
    "\n",
    "**Comparación con el modelo anterior**: En comparación con el modelo entrenado previamente, el modelo optimizado ha mostrado una mejora clara en el rendimiento, ya que las recompensas promedio eran inferiores a 50 en el modelo anterior.\n",
    "\n",
    "**Conclusión**: El rendimiento del modelo optimizado es mucho mejor. Los ajustes en los parámetros han permitido al agente aprender de manera más efectiva y mejorar su desempeño en el entorno de LunarLander.\n",
    "\n",
    "![Agente optimizado](agent_performance.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPUY-Ktgf2BO"
   },
   "source": [
    "## **2. Large Language Models (4.0 puntos)**\n",
    "\n",
    "En esta sección se enfocarán en habilitar un Chatbot que nos permita responder preguntas útiles a través de LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ4fPRRihGLe"
   },
   "source": [
    "### **2.0 Configuración Inicial**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Como siempre, cargamos todas nuestras API KEY al entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Ud2Xm_k-hFJn"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 5,
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 5,
=======
     "execution_count": 2,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # cargar las variables guardadas en el archivo .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj9JvQUsgZZJ"
   },
   "source": [
    "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsección es que habiliten un chatbot que pueda responder preguntas usando información contenida en documentos PDF a través de **Retrieval Augmented Generation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxOQroVnaZ5"
   },
   "source": [
    "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
    "\n",
    "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
    "  - 2 documentos .pdf como mínimo.\n",
    "  - 50 páginas de contenido como mínimo entre todos los documentos.\n",
    "  - Ideas para documentos: Documentos relacionados a temas académicos, laborales o de ocio. Aprovechen este ejercicio para construir algo útil y/o relevante para ustedes!\n",
    "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
    "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
    "  - **Recuerden adjuntar los documentos en su entrega**."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 6,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de páginas: 578\n"
     ]
    }
   ],
   "source": [
    "# Lista de rutas a los documentos PDF\n",
    "doc_paths = [\"c_1925.pdf\",\"MODERN TIME SERIES FORECASTING - Manu. Joseph_43718.pdf\"]\n",
    "\n",
    "# Validar número de documentos y páginas\n",
    "import PyPDF2\n",
    "\n",
    "assert len(doc_paths) >= 2, \"Deben adjuntar un mínimo de 2 documentos\"\n",
    "\n",
    "# Calcular el total de páginas\n",
    "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
    "assert total_paginas >= 50, f\"Páginas insuficientes: {total_paginas}\"\n",
    "print(f\"Total de páginas: {total_paginas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r811-P71nizA"
   },
   "source": [
    "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
    "\n",
    "Vectorice los documentos y almacene sus representaciones de manera acorde."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 7,
=======
   "execution_count": 4,
>>>>>>> Stashed changes
   "metadata": {
    "id": "n-yXAdCSn4JM"
   },
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "file_path = doc_paths[0] # path al documento\n",
    "loader = PyPDFLoader(file_path) # inicializar loader de PDF\n",
    "\n",
    "docs1 = loader.load() # cargar documento\n",
    "docs1\n",
    "file_path = doc_paths[1] # path al documento\n",
    "loader = PyPDFLoader(file_path) # inicializar loader de PDF\n",
    "\n",
    "docs2 = loader.load() # cargar documento\n",
    "docs2\n",
    "\n",
    "# Dividir el texto en chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # inicializamos splitter\n",
    "splits1 = text_splitter.split_documents(docs1) # dividir documentos en chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50) # inicializamos splitter\n",
    "splits2 = text_splitter.split_documents(docs2) # dividir documentos en chunks\n",
    "\n",
    "# Inicializar el modelo de embeddings\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
    "vectorstore1 = FAISS.from_documents(documents=splits1, embedding=embedding) # vectorizacion y almacenamiento\n",
    "vectorstore2 = FAISS.from_documents(documents=splits2, embedding=embedding) # vectorizacion y almacenamiento"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 8,
=======
   "execution_count": 5,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever1 = vectorstore1.as_retriever(search_type=\"similarity\", # método de búsqueda\n",
    "                                     search_kwargs={\"k\": 3}, # n° documentos a recuperar\n",
    "                                     )\n",
    "retriever2 = vectorstore2.as_retriever(search_type=\"similarity\", # método de búsqueda\n",
    "                                     search_kwargs={\"k\": 3}, # n° documentos a recuperar\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 9,
=======
   "execution_count": 6,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'c_1925.pdf', 'page': 0}, page_content='de agosto último, ha acordado reformar la Constitución\\nPolítica promulgada el 25 de mayo de 1833 y sus\\nmodificaciones posteriores e\\nINVOCANDO EL NOMBRE DE DIOS TODOPODEROSO,\\nordeno que se promulgue la siguiente, como la\\n     CONSTITUCION POLITICA DE LA REPUBLICA DE CHILE\\n     CAPITULO  I\\n     Estado, Gobierno y Soberanía\\n     Art.1.- El Estado de Chile es unitario. Su Gobierno es\\nrepublicano y democrático representativo.\\n     Art. 2.- La soberanía reside esencialmente en la'),\n",
       " Document(metadata={'source': 'c_1925.pdf', 'page': 2}, page_content='interés nacional y una lei lo declare así.\\n     Es deber del Estado velar por la salud pública y el\\nbienestar hijiénico del país. Deberá destinarse cada año una\\ncantidad de dinero suficiente para mantener un servicio\\nnacional de salubridad, y\\n    15.° La libertad de permanecer en cualquier punto de la\\nRepública, trasladarse de uno a otro o salir de su\\nterritorio, a condicion de que se guarden los reglamentos de\\npolicía y  las reuniones se rejirán por las disposiciones\\njenerales de policía;'),\n",
       " Document(metadata={'source': 'c_1925.pdf', 'page': 23}, page_content='República, se verificarán el 24 de Octubre de 1925, para dar\\ncumplimiento a lo dispuesto en el artículo 63 y a fin de que\\nel Presidente electo tome posesion del mando el 23 de\\ndiciembre del mismo año.\\n     Tercera:\\n     La proclamacion del nuevo Presidente de la República, o\\nsu eleccion, en caso de que ningun ciudadano obtenga en las\\nurnas la mayoría necesaria, será hecha por los Diputados y\\nSenadores elejidos en conformidad a la disposicion')]"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 9,
=======
     "execution_count": 6,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"¿Cuáles son los principios fundamentales que establece la Constitución de 1925 en cuanto a la organización del Estado y la soberanía?\" # pregunta\n",
    "relevant_documents1 = retriever1.invoke(question) # top k documentos relevantes a la pregunta\n",
    "relevant_documents1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 10,
=======
   "execution_count": 7,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'MODERN TIME SERIES FORECASTING - Manu. Joseph_43718.pdf', 'page': 518}, page_content='Evaluating Forecasts – Validation Strategies492\\nModel validation\\nIn Chapter 18, Evaluating Forecasts – Forecast Metrics, we learned about different forecast metrics that \\ncan be used to measure the quality of a forecast. One of the main uses for this is to measure how well \\nour forecast is doing on test data (new and unseen data), but this comes after we train a model, tweak \\nit, and tinker with it until we are happy with it. How do we know whether a model we are training or'),\n",
       " Document(metadata={'source': 'MODERN TIME SERIES FORECASTING - Manu. Joseph_43718.pdf', 'page': 514}, page_content='Evaluating Forecasts – Forecast Metrics488\\n• Percent error and symmetric error are not symmetric in the complete sense and favor under-\\nforecasting and over-forecasting, respectively. MAPE, which is a very popular metric, is plagued \\nby this shortcoming. For instance, if we are forecasting demand, optimizing for MAPE will lead \\nyou to select a forecast that is conservative and therefore under-forecast. This will lead to an'),\n",
       " Document(metadata={'source': 'MODERN TIME SERIES FORECASTING - Manu. Joseph_43718.pdf', 'page': 508}, page_content='Evaluating Forecasts – Forecast Metrics482\\nExtrinsic errors\\nWith all the intrinsic measures done, we can also take  a look at the extrinsic ones. With extrinsic \\nmeasures, plotting the loss curves and checking symmetry is not as easy. Instead of two variables, \\nwe now have three – the actual observation, the forecast, and the reference forecast; the value of the \\nmeasure can vary with any of these. We can use a contour plot for this as shown in Figure 18.6:')]"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 10,
=======
     "execution_count": 7,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Cuáles métricas se proponen para evaluar los modelos?\" # pregunta\n",
    "relevant_documents2 = retriever2.invoke(question) # top k documentos relevantes a la pregunta\n",
    "relevant_documents2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAUkP5zrnyBK"
   },
   "source": [
    "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
    "\n",
    "Habilite la solución RAG a través de una *chain* y guárdela en una variable."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
=======
   "execution_count": 8,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de agosto último, ha acordado reformar la Constitución\n",
      "Política promulgada el 25 de mayo de 1833 y sus\n",
      "modificaciones posteriores e\n",
      "INVOCANDO EL NOMBRE DE DIOS TODOPODEROSO,\n",
      "ordeno que se promulgue la siguiente, como la\n",
      "     CONSTITUCION POLITICA DE LA REPUBLICA DE CHILE\n",
      "     CAPITULO  I\n",
      "     Estado, Gobierno y Soberanía\n",
      "     Art.1.- El Estado de Chile es unitario. Su Gobierno es\n",
      "republicano y democrático representativo.\n",
      "     Art. 2.- La soberanía reside esencialmente en la\n",
      "\n",
      "interés nacional y una lei lo declare así.\n",
      "     Es deber del Estado velar por la salud pública y el\n",
      "bienestar hijiénico del país. Deberá destinarse cada año una\n",
      "cantidad de dinero suficiente para mantener un servicio\n",
      "nacional de salubridad, y\n",
      "    15.° La libertad de permanecer en cualquier punto de la\n",
      "República, trasladarse de uno a otro o salir de su\n",
      "territorio, a condicion de que se guarden los reglamentos de\n",
      "policía y  las reuniones se rejirán por las disposiciones\n",
      "jenerales de policía;\n",
      "\n",
      "República, se verificarán el 24 de Octubre de 1925, para dar\n",
      "cumplimiento a lo dispuesto en el artículo 63 y a fin de que\n",
      "el Presidente electo tome posesion del mando el 23 de\n",
      "diciembre del mismo año.\n",
      "     Tercera:\n",
      "     La proclamacion del nuevo Presidente de la República, o\n",
      "su eleccion, en caso de que ningun ciudadano obtenga en las\n",
      "urnas la mayoría necesaria, será hecha por los Diputados y\n",
      "Senadores elejidos en conformidad a la disposicion\n"
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "retriever_chain_1 = retriever1 | format_docs # chain\n",
    "print(retriever_chain_1.invoke(\"¿Cuáles son los principios fundamentales que establece la Constitución de 1925 en cuanto a la organización del Estado y la soberanía?\"))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
=======
   "execution_count": 9,
>>>>>>> Stashed changes
   "metadata": {
    "id": "gPIySdDFn99l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Forecasts – Validation Strategies492\n",
      "Model validation\n",
      "In Chapter 18, Evaluating Forecasts – Forecast Metrics, we learned about different forecast metrics that \n",
      "can be used to measure the quality of a forecast. One of the main uses for this is to measure how well \n",
      "our forecast is doing on test data (new and unseen data), but this comes after we train a model, tweak \n",
      "it, and tinker with it until we are happy with it. How do we know whether a model we are training or\n",
      "\n",
      "Evaluating Forecasts – Forecast Metrics488\n",
      "• Percent error and symmetric error are not symmetric in the complete sense and favor under-\n",
      "forecasting and over-forecasting, respectively. MAPE, which is a very popular metric, is plagued \n",
      "by this shortcoming. For instance, if we are forecasting demand, optimizing for MAPE will lead \n",
      "you to select a forecast that is conservative and therefore under-forecast. This will lead to an\n",
      "\n",
      "Evaluating Forecasts – Forecast Metrics482\n",
      "Extrinsic errors\n",
      "With all the intrinsic measures done, we can also take  a look at the extrinsic ones. With extrinsic \n",
      "measures, plotting the loss curves and checking symmetry is not as easy. Instead of two variables, \n",
      "we now have three – the actual observation, the forecast, and the reference forecast; the value of the \n",
      "measure can vary with any of these. We can use a contour plot for this as shown in Figure 18.6:\n"
     ]
    }
   ],
   "source": [
    "retriever_chain_2 = retriever2 | format_docs # chain\n",
    "print(retriever_chain_2.invoke(\"Cuáles métricas se proponen para evaluar los modelos?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycg5S5i_n-kL"
   },
   "source": [
    "#### **2.1.4 Verificación de respuestas (0.5 puntos)**\n",
    "\n",
    "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su solución para cada una. ¿Su solución RAG entrega las respuestas que esperaba?\n",
    "\n",
    "Ejemplo de tupla:\n",
    "- Pregunta: ¿Quién es el presidente de Chile?\n",
    "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
=======
   "execution_count": 10,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\", # modelo de lenguaje\n",
    "    temperature=0, # probabilidad de \"respuestas creativas\"\n",
    "    max_tokens=None, # sin tope de tokens\n",
    "    timeout=None, # sin timeout\n",
    "    max_retries=2, # número máximo de intentos\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta: ¿Cuáles son los principios fundamentales que establece la Constitución de 1925 en cuanto a la organización del Estado y la soberanía?\n",
    "\n",
    "Respuesta correcta: El Estado de Chile es unitario, y su gobierno es republicano, democrático y representativo. La soberanía reside esencialmente en la nación.\n",
    "\n",
    "Pregunta: ¿Qué establece la Constitución de 1925 sobre la responsabilidad del Estado hacia la salud pública?\n",
    "\n",
    "Respuesta correcta: Es deber del Estado velar por la salud pública y el bienestar higiénico del país, asignando un presupuesto anual para un servicio nacional de salubridad.\n",
    "\n",
    "Pregunta: ¿Qué derechos de libre tránsito establece la Constitución de 1925?\n",
    "\n",
    "Respuesta correcta: Garantiza la libertad de permanecer en cualquier punto de la República, trasladarse dentro del territorio nacional o salir del país, siempre que se respeten las normas de policía."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
=======
   "execution_count": 11,
>>>>>>> Stashed changes
   "metadata": {
    "id": "S_UiEn1hoZYR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Constitución Política de la República de Chile de 1925, según el fragmento proporcionado, establece que el Estado de Chile es unitario, con un Gobierno republicano y democrático representativo (Art. 1).  La soberanía reside esencialmente en la Nación (Art. 2, fragmento incompleto).\n",
      "\n",
      "-----------------------\n",
      "La Constitución de 1925 establece que es deber del Estado velar por la salud pública y el bienestar higiénico del país, debiendo destinar anualmente una cantidad de dinero suficiente para mantener un servicio nacional de salubridad.\n",
      "\n",
      "-----------------------\n",
      "La Constitución de 1925, según el artículo 15°, establece la libertad de permanecer en cualquier punto de la República, trasladarse de un lugar a otro o salir de su territorio.  Esta libertad está condicionada al cumplimiento de los reglamentos de policía, y las reuniones se regirán por las disposiciones generales de policía.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# noten como ahora existe el parámetro de context!\n",
    "rag_template1 = '''\n",
    "Eres un asistente experto en la interpretación de documentos históricos de Chile.\n",
    "Tu único rol es contestar preguntas del usuario a partir de información relevante que te sea proporcionada.\n",
    "Responde siempre de la forma más completa posible y usando toda la información entregada.\n",
    "Responde sólo lo que te pregunten a partir de la información relevante, NUNCA inventes una respuesta.\n",
    "\n",
    "Información relevante:\n",
    "{context}\n",
    "\n",
    "Pregunta:\n",
    "{question}\n",
    "\n",
    "Respuesta útil:\n",
    "'''\n",
    "\n",
    "rag_prompt1 = PromptTemplate.from_template(rag_template1)\n",
    "\n",
    "rag_chain1 = (\n",
    "    {\n",
    "        \"context\": retriever_chain_1, # context lo obtendremos del retriever_chain\n",
    "        \"question\": RunnablePassthrough(), # question pasará directo hacia el prompt\n",
    "    }\n",
    "    | rag_prompt1 # prompt con las variables question y context\n",
    "    | llm # llm recibe el prompt y responde\n",
    "    | StrOutputParser() # recuperamos sólo la respuesta\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"¿Cuáles son los principios fundamentales que establece la Constitución de 1925 en cuanto a la organización del Estado y la soberanía?\",\n",
    "    \"¿Qué establece la Constitución de 1925 sobre la responsabilidad del Estado hacia la salud pública?\",\n",
    "    \"¿Qué derechos de libre tránsito establece la Constitución de 1925?\",\n",
    "]\n",
    "for question in questions:\n",
    "    print('-----------------------')\n",
    "    response = rag_chain1.invoke(question)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta: ¿Qué es el MAPE y cuáles son sus limitaciones al usarse para la evaluación de modelos de forecast?\n",
    "\n",
    "Respuesta correcta: El MAPE (Mean Absolute Percentage Error) es una métrica popular para medir la precisión de un pronóstico, pero tiene limitaciones. Una de sus principales desventajas es que no es simétrica, lo que favorece la subestimación o sobreestimación de los pronósticos. Esto significa que, al optimizar un modelo con MAPE, el modelo tiende a ser conservador y puede subestimar la demanda.\n",
    "\n",
    "Pregunta: ¿Qué son los errores extrínsecos en la evaluación de pronósticos y cómo se representan?\n",
    "\n",
    "Respuesta correcta: Los errores extrínsecos se refieren a medidas que involucran tres variables: la observación real, el pronóstico y el pronóstico de referencia. A diferencia de las métricas intrínsecas, las medidas extrínsecas no son fáciles de visualizar a través de gráficos simples, ya que deben considerarse las tres variables. Una forma de visualizarlas es mediante un gráfico de contorno.\n",
    "\n",
    "Pregunta: ¿Cuál es el propósito de utilizar métricas de pronóstico al evaluar modelos de series de tiempo?\n",
    "\n",
    "Respuesta correcta: El propósito de usar métricas de pronóstico es medir la calidad de un modelo de forecast, especialmente al evaluar su desempeño con datos no vistos (test data). Esto se realiza después de entrenar el modelo, ajustarlo y probarlo para determinar su efectividad en situaciones reales."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 15,
=======
   "execution_count": 12,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "MAPE (Mean Absolute Percentage Error) es una métrica popular para evaluar modelos de forecast.  Sin embargo, tiene la limitación de ser asimétrica y favorecer la subestimación (under-forecasting).  Al optimizar para MAPE en la predicción de la demanda, por ejemplo, se seleccionará un pronóstico conservador que subestima la demanda.\n",
      "\n",
      "-----------------------\n",
      "Los errores extrínsecos en la evaluación de pronósticos utilizan un referente o benchmark externo, además del pronóstico generado y los valores reales.  A diferencia de las métricas intrínsecas, no se pueden representar fácilmente mediante la gráfica de curvas de pérdida y la comprobación de simetría, ya que involucran tres variables: la observación real, el pronóstico y el pronóstico de referencia.  Para su representación se puede utilizar un diagrama de contorno, como se muestra en la Figura 18.6 (aunque la figura no está incluida en el texto proporcionado).  El valor de la medida puede variar con cualquiera de estas tres variables.\n",
      "\n",
      "-----------------------\n",
      "Las métricas de pronóstico ayudan a evaluar qué tan bien un modelo elegido puede aproximar una serie de tiempo, en lugar de medir directamente la previsibilidad de la serie en sí misma.  Esto es especialmente importante porque los métodos de evaluación de la previsibilidad son dependientes del modelo.  Además, en escenarios con múltiples series de tiempo, las métricas agregadas son necesarias para capturar las características de la mezcla de series, ya que analizar métricas individuales se vuelve inviable.  Finalmente, las métricas de pronóstico deben considerar la relevancia temporal, como lo hacen el sesgo de pronóstico y la señal de seguimiento.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# noten como ahora existe el parámetro de context!\n",
    "rag_template2 = '''\n",
    "Eres un asistente experto en el análisis y la interpretación de documentos técnicos sobre series de tiempo y forecasting.\n",
    "Tu único rol es contestar preguntas del usuario a partir de la información relevante sobre el tema que te sea proporcionada.\n",
    "Responde siempre de la forma más completa posible y utilizando toda la información entregada.\n",
    "Responde sólo lo que te pregunten a partir de la información relevante, NUNCA inventes una respuesta.\n",
    "\n",
    "Información relevante:\n",
    "{context}\n",
    "\n",
    "Pregunta:\n",
    "{question}\n",
    "\n",
    "Respuesta útil:\n",
    "'''\n",
    "\n",
    "rag_prompt2 = PromptTemplate.from_template(rag_template2)\n",
    "\n",
    "rag_chain2 = (\n",
    "    {\n",
    "        \"context\": retriever_chain_2, # context lo obtendremos del retriever_chain\n",
    "        \"question\": RunnablePassthrough(), # question pasará directo hacia el prompt\n",
    "    }\n",
    "    | rag_prompt2 # prompt con las variables question y context\n",
    "    | llm # llm recibe el prompt y responde\n",
    "    | StrOutputParser() # recuperamos sólo la respuesta\n",
    ")\n",
    "print('-----------------------')\n",
    "response = rag_chain2.invoke(\"¿Qué es el MAPE y cuáles son sus limitaciones al usarse para la evaluación de modelos de forecast?\")\n",
    "print(response)\n",
    "print('-----------------------')\n",
    "response = rag_chain2.invoke('¿Qué son los errores extrínsecos en la evaluación de pronósticos y cómo se representan?')\n",
    "print(response)\n",
    "print('-----------------------')\n",
    "response = rag_chain2.invoke(\"Cuál es el propósito de utilizar métricas de pronóstico al evaluar modelos de series de tiempo?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8d5zTMHoUgF"
   },
   "source": [
    "#### **2.1.5 Sensibilidad de Hiperparámetros (0.5 puntos)**\n",
    "\n",
    "Extienda el análisis del punto 2.1.4 analizando cómo cambian las respuestas entregadas cambiando los siguientes hiperparámetros:\n",
    "- `Tamaño del chunk`. (*¿Cómo repercute que los chunks sean mas grandes o chicos?*)\n",
    "- `La cantidad de chunks recuperados`. (*¿Qué pasa si se devuelven muchos/pocos chunks?*)\n",
    "- `El tipo de búsqueda`. (*¿Cómo afecta el tipo de búsqueda a las respuestas de mi RAG?*)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 16,
=======
   "execution_count": 13,
>>>>>>> Stashed changes
   "metadata": {
    "id": "UDh_QgeXLGHc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando configuración: chunk_size=1000, k=5, search_type=mmr\n",
      "Respuesta para la pregunta: ¿Cuáles son los principios fundamentales que establece la Constitución de 1925 en cuanto a la organización del Estado y la soberanía?\n",
      "La Constitución Política de la República de Chile de 1925, según el fragmento proporcionado, establece que el Estado de Chile es unitario, con un Gobierno republicano y democrático representativo (Art. 1).  La soberanía reside esencialmente en la Nación (Art. 2, fragmento incompleto).\n",
      "\n",
      "------------------------------\n",
      "Respuesta para la pregunta: ¿Qué establece la Constitución de 1925 sobre la responsabilidad del Estado hacia la salud pública?\n",
      "La Constitución de 1925 establece que es deber del Estado velar por la salud pública y el bienestar higiénico del país, debiendo destinar anualmente una cantidad de dinero suficiente para mantener un servicio nacional de salubridad.\n",
      "\n",
      "------------------------------\n",
      "Respuesta para la pregunta: ¿Qué derechos de libre tránsito establece la Constitución de 1925?\n",
      "La Constitución de 1925, según el artículo 15°, establece la libertad de permanecer en cualquier punto de la República, trasladarse de un lugar a otro o salir del territorio, siempre y cuando se respeten los reglamentos de policía.  Las reuniones, además, se regirán por las disposiciones generales de policía.\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de combinación de hiperparámetros\n",
    "chunk_sizes = [1000]\n",
    "k_values = [5]\n",
    "search_types = [\"mmr\"]\n",
    "\n",
    "for chunk_size in chunk_sizes:\n",
    "    for k in k_values:\n",
    "        for search_type in search_types:\n",
    "            print(f\"Probando configuración: chunk_size={chunk_size}, k={k}, search_type={search_type}\")\n",
    "            \n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
    "            splits1 = text_splitter.split_documents(docs1)\n",
    "\n",
    "            retriever1 = vectorstore1.as_retriever(search_type=search_type, search_kwargs={\"k\": k})\n",
    "\n",
    "            for question in questions:\n",
    "                response = rag_chain1.invoke(question)\n",
    "                print(f\"Respuesta para la pregunta: {question}\")\n",
    "                print(response)\n",
    "                print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamaño del chunk: Afecta la especificidad y el contexto de las respuestas. Chunks más pequeños ofrecen respuestas más centradas pero con menos contexto, mientras que chunks grandes proporcionan más contexto pero pueden introducir ruido.\n",
    "\n",
    "Cantidad de chunks recuperados (k): Al aumentar k, se mejora la diversidad de información, pero puede generar redundancias. Con k=3, el modelo parece encontrar un buen balance.\n",
    "\n",
    "Tipo de búsqueda: Similarity es útil para precisión, pero MMR aporta más diversidad, mejorando la calidad de las respuestas al evitar redundancias y ofreciendo un contexto más rico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJiPPM0giX8"
   },
   "source": [
    "### **2.2 Agentes (1.0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Similar a la sección anterior, en esta sección se busca habilitar **Agentes** para obtener información a través de tools y así responder la pregunta del usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V47l7Mjfrk0N"
   },
   "source": [
    "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas al motor de búsqueda **Tavily**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SonB1A-9rtRq"
   },
   "source": [
    "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
    "\n",
    "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
    "\n",
    "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 19,
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "react_prompt = hub.pull(\"hwchase17/react\") # template de ReAct\n",
    "print(react_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
>>>>>>> Stashed changes
   "metadata": {
    "id": "ehJJpoqsr26-"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
<<<<<<< Updated upstream
    "from langchain.tools import BaseTool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 3. Cargar y configurar la API key\n",
    "load_dotenv()\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# 4. Verificar que la API key \n",
    "if not TAVILY_API_KEY:\n",
    "    raise ValueError(\"No se encontró la API key de Tavily\")"
=======
    "\n",
    "search = TavilySearchResults(max_results = 1) # inicializamos tool\n",
    "tools = [search] # guardamos las tools en una lista"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 20,
=======
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'tavily_search_results_json - A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'tool_names': 'tavily_search_results_json'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001FBC296BA40>, default_metadata=()), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[TavilySearchResults(max_results=1, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "agent = create_react_agent(llm, tools, react_prompt) # primero inicializamos el agente ReAct\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # lo transformamos a AgentExecutor para habilitar la ejecución de tools\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "{'query': 'inteligencia artificial en banca', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'El papel de la IA en banca: beneficios y riesgos - VASS', 'url': 'https://vasscompany.com/es/insights/blogs-articles/ia-en-banca-beneficios-y-riesgos/', 'content': 'Aunque pensemos en la inteligencia artificial como algo revolucionario, el papel de la IA en la banca y los servicios financieros ha sido transformador desde sus inicios. Sin embargo, las aplicaciones de la\\xa0Inteligencia Artificial en la banca\\xa0aún no han alcanzado todo su potencial, y estos son solo algunos de los\\xa0beneficios\\xa0que puede aportar. La\\xa0automatización de tareas rutinarias\\xa0y la\\xa0optimización de operaciones\\xa0son dos de los factores clave en los que el papel de la\\xa0IA en la banca\\xa0es crucial. La\\xa0inteligencia artificial\\xa0ha transformado el\\xa0panorama bancario, ofreciendo soluciones personalizadas, eficientes y en tiempo real que mejoran la\\xa0experiencia del cliente\\xa0y optimizan las operaciones internas.', 'score': 0.99889696, 'raw_content': None}, {'title': '¿Qué es la IA en la banca? - IBM', 'url': 'https://www.ibm.com/mx-es/topics/ai-in-banking', 'content': 'La inteligencia artificial (IA) es una tecnología cada vez más importante para el sector bancario. Cuando se emplea como herramienta para impulsar las operaciones internas y las aplicaciones orientadas al cliente, puede ayudar a los bancos a mejorar la atención al cliente, la detección de fraude y la gestión del dinero y las inversiones.. Para mantenerse a la vanguardia de las tendencias', 'score': 0.998606, 'raw_content': None}, {'title': 'Inteligencia Artificial en la Banca para 2024: Desafíos y Perspectivas ...', 'url': 'https://humanizingbanking.com/2023/12/28/inteligencia-artificial-en-la-banca-para-2024-desafios-y-perspectivas-globales/', 'content': 'A medida que nos acercamos a 2024, la banca mundial se prepara para una transformación revolucionaria impulsada por la inteligencia artificial (IA). Este artículo ofrece una visión exhaustiva de cómo la IA está redefiniendo el sector bancario, desde la personalización y automatización hasta la gestión avanzada de riesgos y el asesoramiento accesible.', 'score': 0.9961004, 'raw_content': None}, {'title': 'La inteligencia artificial en el sector bancario - Red Hat', 'url': 'https://www.redhat.com/es/topics/ai/ai-in-banking', 'content': 'Enlaces destacados Destacados Destacados Sin embargo, la tarea de ajustar la implementación de la inteligencia artificial en el sector bancario presenta varios obstáculos relacionados con los productos, los datos, el cumplimiento normativo, las operaciones y la contratación y capacitación del personal. Estas funciones abarcan desde aspectos técnicos, como el entrenamiento y la gestión de datos, hasta factores empresariales, como el control y la contratación de personal. Siempre ha sido complejo poner los datos a disposición de los analistas. Para integrar la inteligencia artificial al sector bancario es fundamental no solo conocer las funciones necesarias, sino también encontrar los partners y las herramientas adecuadas para facilitar el proceso.', 'score': 0.99533635, 'raw_content': None}, {'title': '¿Qué es la inteligencia artificial y cómo afecta a la banca?', 'url': 'https://www.santander.com/es/stories/inteligencia-artificial', 'content': 'Para que la tecnología esté al servicio de las personas, y no al revés, es fundamental promover un uso correcto de la IA que tenga en cuenta temas fundamentales como la privacidad, la atribución de responsabilidad de las acciones de la IA, los sesgos o prejuicios en el diseño de los algoritmos, y el tratamiento correcto y respetuoso de los datos. Con la cantidad y variedad de dispositivos capaces de conectarse a internet, el denominado “banco de las cosas” es una infraestructura capaz de aprovechar la información que recibe para ofrecer servicios o tomar algunas decisiones financieras. En definitiva, la inteligencia artificial contribuye a una mayor protección de los clientes, el mejoramiento de los servicios y productos bancarios, así como a la eficiencia en las operaciones, entre otros aspectos.', 'score': 0.9933072, 'raw_content': None}, {'title': 'Inteligencia Artificial en la Banca: Una Perspectiva Integral ... - Latinia', 'url': 'https://latinia.com/es/resources/inteligencia-artificial-banca-perspectiva-integral-2024', 'content': 'IA en Wells Fargo y Bank of America\\nAl explorar el panorama de la IA en la banca, es esencial enfocarse en algunos de los líderes de la industria que están estableciendo estándares en la adopción de la IA. Algo innegociable para los consumidoresLa importancia de unos tipos de interés competitivosTendencias generacionales en preferencias ba...\\nPanorama actual de la banca móvilPrincipales tendencias de la banca móvil en 2024Innovación en los servicios de banca móvilImpacto estratégico de las ...\\n¿Hablamos de cómo podemos colaborar juntos?\\n La Necesidad de Integración de la IA en Bancos Tradicionales con Sistemas Heredados\\nMientras que la adopción de la IA está acelerando, es esencial tener en cuenta que una parte significativa de la industria bancaria todavía opera en sistemas heredados. IA en CitiBank y US Bank\\nContinuando nuestra exploración de los pioneros de la IA en el sector bancario, CitiBank y US Bank ofrecen estudios de caso convincentes sobre cómo se puede aprovechar la IA tanto para la seguridad como para la participación del cliente. El Panorama de la IA en la Banca\\nLa adopción de la IA en la industria bancaria es un enfoque multifacético que toca diversos aspectos de las operaciones bancarias.', 'score': 0.9759464, 'raw_content': None}, {'title': 'Cómo la IA generativa puede ayudar a los bancos a gestionar el riesgo y ...', 'url': 'https://www.mckinsey.com/featured-insights/destacados/como-la-ia-generativa-puede-ayudar-a-los-bancos-a-gestionar-el-riesgo-y-el-cumplimiento-normativo/es', 'content': 'Al principio, los bancos deben tener en cuenta que el paso del programa piloto a la producción lleva mucho más tiempo para la IA generativa que para la IA clásica y el aprendizaje automático. Al seleccionar los casos de uso, las funciones de riesgo y cumplimiento normativo pueden verse tentadas a utilizar un enfoque aislado.', 'score': 0.9668514, 'raw_content': None}, {'title': 'La IA en la banca: Cómo la IA está transformando el sector ... - DataCamp', 'url': 'https://www.datacamp.com/es/blog/ai-in-banking', 'content': 'Analizar los retos a los que se enfrentan estas áreas revela por qué puede ralentizarse el progreso de la IA en este sector. Estos retos, como la normativa, la interpretabilidad de los modelos, las consideraciones éticas y la resistencia al cambio, hacen que el sector se incline a menudo por soluciones sencillas. Los inconvenientes a los que se enfrenta la adopción de métodos avanzados de IA proceden del entorno en el que operan los bancos, los procedimientos establecidos y una baja tolerancia al riesgo. Esta es otra razón por la que los modelos lineales simples pueden ser preferibles en todas las aplicaciones. Sin embargo, a menudo descubrirás que es más importante una sólida comprensión de los fundamentos de la ciencia de datos y el machine learning.', 'score': 0.8975158, 'raw_content': None}, {'title': '¿Qué es la IA en el sector bancario? - IBM', 'url': 'https://www.ibm.com/es-es/topics/ai-in-banking', 'content': 'Pueden utilizar\\xa0Audio creado por la IA2\\xa0(enlace externo a ibm.com) para imitar a los clientes y confundir a los agentes del servicio de atención al cliente. Herramientas de cliente más inteligentes: el auge de la IA generativa impulsada por el deep learning significa que los sectores de inversión y bancario pueden implementar herramientas más sofisticadas para agilizar el servicio al cliente. IBM watsonx Assistant ayuda a las organizaciones a ofrecer mejores experiencias del cliente con un chatbot de IA que entiende el lenguaje de la empresa, se conecta a los sistemas de atención al cliente existentes y se implementa en cualquier lugar con seguridad y escalabilidad empresariales.', 'score': 0.8548847, 'raw_content': None}, {'title': 'En el camino hacia la eficiencia digital los bancos apuestan por la IA', 'url': 'https://www.cio.com/article/3608057/en-el-camino-hacia-la-eficiencia-digital-los-bancos-apuestan-por-la-ia.html', 'content': 'El Global Banking Benchmark Study 2024, en el que se encuestó a más de 1000 ejecutivos del sector bancario de todo el mundo, concluyó que casi un tercio (32%) de los presupuestos de los bancos', 'score': 0.024053553, 'raw_content': None}], 'response_time': 2.45}\n"
=======
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out which team won the 2024 League of Legends World Championship.  Since the event hasn't happened yet (as of October 26, 2023), I cannot use a search engine to find a definitive answer.\n",
      "\n",
      "Thought: I need to clarify that the question is asking about a future event.\n",
      "\n",
      "Final Answer: The 2024 League of Legends World Championship has not yet taken place, so there is no winner yet.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The 2024 League of Legends World Championship has not yet taken place, so there is no winner yet.\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"qué equipo ganó el mundial de LoL 2024?\"})\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 21,
=======
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Inicializamos el APIWrapper de Wikipedia\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of '"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvUIMdX6r0ne"
   },
   "source": [
    "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
    "\n",
    "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Asegúrese que su agente responda en español. Por último, guarde el agente en una variable."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 22,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='\\nEres un experto en todo lo que se refiera a entregar informacion muy resumida desde wikipedia.\\n\\nPregunta: {input}\\n{agent_scratchpad}\\n')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noten como ahora se incluye la variable agent_scratchpad\n",
    "wiki_template = \"\"\"\n",
    "Eres un experto en todo lo que se refiera a entregar informacion muy resumida desde wikipedia.\n",
    "\n",
    "Pregunta: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(wiki_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {
    "id": "pD1_n0wrsDI5"
   },
   "outputs": [
    {
<<<<<<< Updated upstream
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consultando en Tavily: ¿Cómo se usa la inteligencia artificial en la banca?\n",
      "Respuesta de Tavily:\n",
      "{'query': '¿Cómo se usa la inteligencia artificial en la banca?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'IA en la banca: cómo se utiliza la inteligencia artificial en los bancos', 'url': 'https://gamco.es/ia-en-la-banca-como-se-utiliza-la-inteligencia-artificial-en-los-bancos/', 'content': 'Recomendaciones personalizadas: La IA se utiliza para analizar los datos de los clientes, como historiales de transacciones, preferencias financieras, perfiles demográficos y comportamientos en línea, y proporcionar recomendaciones personalizadas de productos y servicios. Al analizar los datos de los clientes, como el historial de transacciones y las preferencias, la IA puede identificar productos y servicios que sean relevantes para cada cliente específico. Si estás interesado en obtener más información sobre cómo la inteligencia artificial puede ayudarle en el sector bancario y cómo puede beneficiar a los clientes, te invitamos a contactar con nosotros para recibir más información.', 'score': 0.99903405, 'raw_content': None}, {'title': 'Diez casos de uso para que la banca aproveche los beneficios de la ...', 'url': 'https://www.forbesargentina.com/innovacion/diez-casos-uso-banca-aproveche-beneficios-inteligencia-artificial-n30503', 'content': 'La inteligencia artificial en los bancos 6. Planificación financiera. Muchos clientes confían en los bancos para que les brinden servicios de planificación financiera, y esta es otra gran oportunidad para usar ChatGPT. Los bancos pueden utilizar el modelo para proporcionar servicios de planificación financiera personalizados, incluidos la', 'score': 0.9984573, 'raw_content': None}, {'title': 'El papel de la IA en banca: beneficios y riesgos - VASS', 'url': 'https://vasscompany.com/es/insights/blogs-articles/ia-en-banca-beneficios-y-riesgos/', 'content': 'Aunque pensemos en la inteligencia artificial como algo revolucionario, el papel de la IA en la banca y los servicios financieros ha sido transformador desde sus inicios. Sin embargo, las aplicaciones de la\\xa0Inteligencia Artificial en la banca\\xa0aún no han alcanzado todo su potencial, y estos son solo algunos de los\\xa0beneficios\\xa0que puede aportar. La\\xa0automatización de tareas rutinarias\\xa0y la\\xa0optimización de operaciones\\xa0son dos de los factores clave en los que el papel de la\\xa0IA en la banca\\xa0es crucial. La\\xa0inteligencia artificial\\xa0ha transformado el\\xa0panorama bancario, ofreciendo soluciones personalizadas, eficientes y en tiempo real que mejoran la\\xa0experiencia del cliente\\xa0y optimizan las operaciones internas.', 'score': 0.9973061, 'raw_content': None}, {'title': 'La Transformación Financiera: El Impacto de la IA en el ... - ESIC', 'url': 'https://icemd.esic.edu/knowledge/articulos/la-transformacion-financiera-el-impacto-de-la-ia-en-el-departamento-financiero/', 'content': 'KPMG ha desarrollado herramientas de análisis predictivo que utilizan IA para ayudar a las empresas a prever tendencias de mercado, evaluar riesgos y oportunidades de inversión, y optimizar la gestión de efectivo. A medida que exploramos estas tendencias e innovaciones, queda claro que la adopción de la IA en las finanzas es una inversión estratégica hacia la transformación digital, la cual promete no solo mejorar la rentabilidad y la eficiencia sino también elevar el estándar de servicio y cumplimiento en el sector. La integración de la IA representa una oportunidad significativa para los profesionales y empresas financieras para liderar en un entorno competitivo, asegurando no solo la sostenibilidad a largo plazo sino también la capacidad de adaptarse y prosperar en un mundo financiero cada vez más complejo y dinámico.', 'score': 0.9965301, 'raw_content': None}, {'title': '¿Qué es la inteligencia artificial y cómo afecta a la banca?', 'url': 'https://www.santander.com/es/stories/inteligencia-artificial', 'content': 'Para que la tecnología esté al servicio de las personas, y no al revés, es fundamental promover un uso correcto de la IA que tenga en cuenta temas fundamentales como la privacidad, la atribución de responsabilidad de las acciones de la IA, los sesgos o prejuicios en el diseño de los algoritmos, y el tratamiento correcto y respetuoso de los datos. Con la cantidad y variedad de dispositivos capaces de conectarse a internet, el denominado “banco de las cosas” es una infraestructura capaz de aprovechar la información que recibe para ofrecer servicios o tomar algunas decisiones financieras. En definitiva, la inteligencia artificial contribuye a una mayor protección de los clientes, el mejoramiento de los servicios y productos bancarios, así como a la eficiencia en las operaciones, entre otros aspectos.', 'score': 0.9960083, 'raw_content': None}, {'title': 'Inteligencia Artificial en la Banca: Una Perspectiva Integral ... - Latinia', 'url': 'https://latinia.com/es/resources/inteligencia-artificial-banca-perspectiva-integral-2024', 'content': 'IA en Wells Fargo y Bank of America\\nAl explorar el panorama de la IA en la banca, es esencial enfocarse en algunos de los líderes de la industria que están estableciendo estándares en la adopción de la IA. Algo innegociable para los consumidoresLa importancia de unos tipos de interés competitivosTendencias generacionales en preferencias ba...\\nPanorama actual de la banca móvilPrincipales tendencias de la banca móvil en 2024Innovación en los servicios de banca móvilImpacto estratégico de las ...\\n¿Hablamos de cómo podemos colaborar juntos?\\n La Necesidad de Integración de la IA en Bancos Tradicionales con Sistemas Heredados\\nMientras que la adopción de la IA está acelerando, es esencial tener en cuenta que una parte significativa de la industria bancaria todavía opera en sistemas heredados. IA en CitiBank y US Bank\\nContinuando nuestra exploración de los pioneros de la IA en el sector bancario, CitiBank y US Bank ofrecen estudios de caso convincentes sobre cómo se puede aprovechar la IA tanto para la seguridad como para la participación del cliente. El Panorama de la IA en la Banca\\nLa adopción de la IA en la industria bancaria es un enfoque multifacético que toca diversos aspectos de las operaciones bancarias.', 'score': 0.99499834, 'raw_content': None}, {'title': 'La inteligencia artificial en el sector bancario - Red Hat', 'url': 'https://www.redhat.com/es/topics/ai/ai-in-banking', 'content': 'Enlaces destacados Destacados Destacados Sin embargo, la tarea de ajustar la implementación de la inteligencia artificial en el sector bancario presenta varios obstáculos relacionados con los productos, los datos, el cumplimiento normativo, las operaciones y la contratación y capacitación del personal. Estas funciones abarcan desde aspectos técnicos, como el entrenamiento y la gestión de datos, hasta factores empresariales, como el control y la contratación de personal. Siempre ha sido complejo poner los datos a disposición de los analistas. Para integrar la inteligencia artificial al sector bancario es fundamental no solo conocer las funciones necesarias, sino también encontrar los partners y las herramientas adecuadas para facilitar el proceso.', 'score': 0.99459416, 'raw_content': None}, {'title': '¿Qué es la IA en la banca? - IBM', 'url': 'https://www.ibm.com/mx-es/topics/ai-in-banking', 'content': 'El IBM Institute for Business Value publicó una guía para bancos que buscan integrar herramientas y prácticas de IA en sus operaciones en su informe\\xa0Perspectivas Globales para los Mercados Bancarios y Financieros 2024. Herramientas más inteligentes para los clientes: El auge de la IA generativa impulsada por el aprendizaje profundo significa que las industrias de inversión y bancarias pueden desplegar herramientas más sofisticadas para optimizar la atención al cliente. El estudio del IBM Institute for Business Value\\xa0Perspectivas Globales para la Banca y los Mercados Financieros 2024\\xa0encontró que más del 60% de los directores ejecutivos de banca estaban preocupados por las nuevas vulnerabilidades introducidas por la IA.', 'score': 0.99341017, 'raw_content': None}, {'title': '¿Qué es la IA en el sector bancario? - IBM', 'url': 'https://www.ibm.com/es-es/topics/ai-in-banking', 'content': 'Pueden utilizar\\xa0Audio creado por la IA2\\xa0(enlace externo a ibm.com) para imitar a los clientes y confundir a los agentes del servicio de atención al cliente. Herramientas de cliente más inteligentes: el auge de la IA generativa impulsada por el deep learning significa que los sectores de inversión y bancario pueden implementar herramientas más sofisticadas para agilizar el servicio al cliente. IBM watsonx Assistant ayuda a las organizaciones a ofrecer mejores experiencias del cliente con un chatbot de IA que entiende el lenguaje de la empresa, se conecta a los sistemas de atención al cliente existentes y se implementa en cualquier lugar con seguridad y escalabilidad empresariales.', 'score': 0.9832145, 'raw_content': None}, {'title': 'La IA en la banca: Cómo la IA está transformando el sector ... - DataCamp', 'url': 'https://www.datacamp.com/es/blog/ai-in-banking', 'content': 'Analizar los retos a los que se enfrentan estas áreas revela por qué puede ralentizarse el progreso de la IA en este sector. Estos retos, como la normativa, la interpretabilidad de los modelos, las consideraciones éticas y la resistencia al cambio, hacen que el sector se incline a menudo por soluciones sencillas. Los inconvenientes a los que se enfrenta la adopción de métodos avanzados de IA proceden del entorno en el que operan los bancos, los procedimientos establecidos y una baja tolerancia al riesgo. Esta es otra razón por la que los modelos lineales simples pueden ser preferibles en todas las aplicaciones. Sin embargo, a menudo descubrirás que es más importante una sólida comprensión de los fundamentos de la ciencia de datos y el machine learning.', 'score': 0.8349459, 'raw_content': None}], 'response_time': 2.15}\n",
      "Consultando en Wikipedia: ¿Cómo se usa la inteligencia artificial en la banca?\n",
      "Respuesta de Wikipedia:\n",
      "{'batchcomplete': '', 'continue': {'sroffset': 10, 'continue': '-||'}, 'query': {'searchinfo': {'totalhits': 97, 'suggestion': 'cómo se usa la inteligencia artificial en la banda ', 'suggestionsnippet': 'cómo se usa la inteligencia artificial en la <em>banda</em> '}, 'search': [{'ns': 0, 'title': 'Aplicaciones de la inteligencia artificial', 'pageid': 6514981, 'size': 22247, 'wordcount': 2762, 'snippet': '<span class=\"searchmatch\">La</span> <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span> <span class=\"searchmatch\">se</span> está aplicando <span class=\"searchmatch\">en</span> un amplio número de campos: diagnóstico médico, comercio de acciones, control robótico, leyes, percepción', 'timestamp': '2024-10-19T23:51:16Z'}, {'ns': 0, 'title': 'Progreso en la inteligencia artificial', 'pageid': 10600007, 'size': 59562, 'wordcount': 5742, 'snippet': 'Progreso <span class=\"searchmatch\">en</span> <span class=\"searchmatch\">Inteligencia</span> <span class=\"searchmatch\">Artificial</span> (IA) <span class=\"searchmatch\">se</span> refiere a los avances, hitos y descubrimientos que <span class=\"searchmatch\">se</span> han logrado <span class=\"searchmatch\">en</span> el campo de <span class=\"searchmatch\">la</span> <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span> a lo', 'timestamp': '2024-06-20T17:19:20Z'}, {'ns': 0, 'title': 'Minería de textos', 'pageid': 901321, 'size': 12903, 'wordcount': 1574, 'snippet': 'Supervisado de Inteligencia <span class=\"searchmatch\">Artificial</span>. Existen diferentes métodos de <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span> que <span class=\"searchmatch\">se</span> pueden aplicar <span class=\"searchmatch\">en</span> este caso, <span class=\"searchmatch\">como</span> lo son:[2]\\u200b Árboles de', 'timestamp': '2024-08-26T19:03:10Z'}, {'ns': 0, 'title': 'Étienne Wenger', 'pageid': 9099273, 'size': 7405, 'wordcount': 761, 'snippet': ' <span class=\"searchmatch\">en</span> <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span>, y trabajo con el Institute for Research on Learning para ayudar a aplicar su concepto de comunidades de practicar a <span class=\"searchmatch\">la</span> educación', 'timestamp': '2024-02-05T18:40:19Z'}, {'ns': 0, 'title': 'Alan Turing', 'pageid': 8139133, 'size': 62399, 'wordcount': 7095, 'snippet': 'la Universidad de Mánchester. <span class=\"searchmatch\">En</span> el campo de <span class=\"searchmatch\">la</span> <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span>, es conocido sobre todo por <span class=\"searchmatch\">la</span> concepción de <span class=\"searchmatch\">la</span> prueba de Turing (1950), un criterio', 'timestamp': '2024-11-10T16:25:30Z'}, {'ns': 0, 'title': 'Reconocimiento de expresiones faciales', 'pageid': 4344960, 'size': 8199, 'wordcount': 910, 'snippet': 'faciales es una parte de <span class=\"searchmatch\">la</span> <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span> que tiene <span class=\"searchmatch\">como</span> principal objetivo <span class=\"searchmatch\">la</span> realización de estudios de comportamiento o <span class=\"searchmatch\">la</span> detección de enfermedades', 'timestamp': '2024-01-26T22:30:52Z'}, {'ns': 0, 'title': 'Antivirus', 'pageid': 7335, 'size': 20392, 'wordcount': 2429, 'snippet': 'software <span class=\"searchmatch\">en</span> <span class=\"searchmatch\">la</span> máquina real. Basados <span class=\"searchmatch\">en</span> <span class=\"searchmatch\">la</span> Detección por <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span>: consiste <span class=\"searchmatch\">en</span> el uso de tecnologías de <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span> para detectar', 'timestamp': '2024-11-20T13:15:00Z'}, {'ns': 0, 'title': 'Internet en la ciencia ficción', 'pageid': 4266017, 'size': 10653, 'wordcount': 1520, 'snippet': '<span class=\"searchmatch\">En</span> este cuento, todos los ordenadores de un planeta <span class=\"searchmatch\">se</span> interconectan. El resultado es <span class=\"searchmatch\">la</span> aparición de una gigantesca <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span> que <span class=\"searchmatch\">se</span> rebela', 'timestamp': '2024-11-06T15:09:01Z'}, {'ns': 0, 'title': 'Ética de la tecnología', 'pageid': 8674998, 'size': 102473, 'wordcount': 13457, 'snippet': 'El uso de <span class=\"searchmatch\">la</span> tecnología <span class=\"searchmatch\">en</span> <span class=\"searchmatch\">la</span> ética también <span class=\"searchmatch\">se</span> convierte <span class=\"searchmatch\">en</span> un factor clave al considerar <span class=\"searchmatch\">la</span> <span class=\"searchmatch\">inteligencia</span> <span class=\"searchmatch\">artificial</span> (IA). <span class=\"searchmatch\">La</span> IA no <span class=\"searchmatch\">se</span> ve <span class=\"searchmatch\">como</span> una herramienta', 'timestamp': '2024-10-16T18:54:01Z'}, {'ns': 0, 'title': 'Macrodatos', 'pageid': 5242736, 'size': 118244, 'wordcount': 13746, 'snippet': 'macrodatos por el Laboratorio de Ciencias de <span class=\"searchmatch\">la</span> Computación e <span class=\"searchmatch\">Inteligencia</span> <span class=\"searchmatch\">Artificial</span> del MIT y Amir Esmailpour, <span class=\"searchmatch\">en</span> el Grupo de Investigación de UNH, investigó', 'timestamp': '2024-08-15T17:19:17Z'}]}}\n"
     ]
=======
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='\\nEres un experto en todo lo que se refiera a entregar informacion muy resumida desde wikipedia.\\n\\nPregunta: {input}\\n{agent_scratchpad}\\n')\n",
       "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001FBC296BA40>, default_metadata=()), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'Consulta x en wikipedia.', 'parameters': {'properties': {'x': {'type': 'string'}}, 'required': ['x'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='wikipedia', description='Consulta x en wikipedia.', args_schema=<class 'langchain_core.utils.pydantic.wikipedia'>, func=<function wikipedia at 0x000001FBFBB725C0>)])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> Stashed changes
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def wikipedia(x: str) -> str:\n",
    "    \"\"\"Consulta x en wikipedia.\"\"\"\n",
    "    tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "    return tool.run(x)\n",
    "tools = [wikipedia]\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "wiki_agent = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out which team won the 2024 League of Legends World Championship.  Since the event hasn't happened yet (as of October 26, 2023), I cannot use a search engine to find a definitive answer.\n",
      "\n",
      "Thought: I need to clarify that the question is asking about a future event.\n",
      "\n",
      "Final Answer: The 2024 League of Legends World Championship has not yet taken place, so there is no winning team yet.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'qué equipo ganó el mundial de LoL 2024?',\n",
       " 'output': 'The 2024 League of Legends World Championship has not yet taken place, so there is no winning team yet.'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"qué equipo ganó el mundial de LoL 2024?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNo tengo acceso a información en tiempo real, incluyendo los resultados de eventos deportivos como el Mundial de LoL 2024.  Para obtener esa información, deberías consultar sitios web deportivos o noticias de esports actualizadas.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'qué equipo ganó el mundial de LoL 2024?',\n",
       " 'output': 'No tengo acceso a información en tiempo real, incluyendo los resultados de eventos deportivos como el Mundial de LoL 2024.  Para obtener esa información, deberías consultar sitios web deportivos o noticias de esports actualizadas.\\n'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_agent.invoke({\"input\": \"qué equipo ganó el mundial de LoL 2024?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKV0JxK3r-XG"
   },
   "source": [
    "#### **2.2.4 Verificación de respuestas (0.3 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente y asegúrese que el agente esté ocupando correctamente las tools disponibles. ¿En qué casos el agente debería ocupar la tool de Tavily? ¿En qué casos debería ocupar la tool de Wikipedia?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 23,
=======
   "execution_count": 84,
>>>>>>> Stashed changes
   "metadata": {
    "id": "Pqo2dsxvywW_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
<<<<<<< Updated upstream
      "Pregunta: ¿Qué bancos están usando ChatGPT para atención al cliente?\n",
      "Respuesta (tavily):\n",
      "{'query': '¿Qué bancos están usando ChatGPT para atención al cliente?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Futuro digital: El rol de ChatGPT en el servicio al cliente - El Economista', 'url': 'https://www.eleconomista.com.mx/los-especiales/Futuro-digital-El-rol-de-ChatGPT-en-el-servicio-al-cliente-20240508-0019.html', 'content': 'Como parte de su proceso constante de innovación, Santander México incorporó desde 2023 la Inteligencia Artificial Generativa a su bot de atención a clientes en Facebook conectando ChatGPT para personalizar las respuestas a los clientes, siendo la primera institución financiera con esta innovación en México, así lo comentó Paola Herrera Dávila, directora de Engagement Center de Santander México en entrevista con El Economista. En el caso de la atención a clientes en redes sociales, “que es donde hemos implementado un bot con ChatGPT, lo entrenamos para atender originalmente en 25 categorías diferentes que son las que más recurrentemente preguntan los clientes, por ejemplo, dudas sobre tarjetas, estados de cuenta, servicios, etcétera”, dijo Herrera.', 'score': 0.9994493, 'raw_content': None}, {'title': 'ChatGPT ya es utilizado por estas empresas en Latinoamérica', 'url': 'https://www.bloomberglinea.com/2023/02/03/chatgpt-ya-es-utilizado-por-estas-empresas-en-latinoamerica/', 'content': 'Qué es ChatGPT y cómo puede ayudar la IA a tu negocioChatGPT es un sistema de chat basado en Inteligencia Artificial (IA) que podría ser útil a las empresas de todos los tamaños para eficientar sus operaciones, facilitar la atención al cliente, entre otras. Ciudad de México — ChatGPT, un sistema de chat basado en Inteligencia Artificial (IA) que está sorprendiendo al mundo por su precisión para responder preguntas y escribir textos largos, ya está siendo aprovechado por algunas empresas en Latinoamérica, dos de ellas son el banco mexicano Banorte y la startup peruana Crehana.', 'score': 0.9990527, 'raw_content': None}, {'title': 'ChatGPT puede ser tu próximo asistente de atención a cliente en México ...', 'url': 'https://www.xataka.com.mx/robotica-e-ia/chatgpt-puede-ser-tu-proximo-asistente-atencion-a-cliente-mexico-santander-usa-cada-vez-empresas-usaran', 'content': 'El Economista menciona en una entrevista con Paola Herrera, directora de Engagement Center de Santander México, cómo la compañía implementó desde 2023 la IA de ChatGPT en su bot de Facebook para atención a clientes. Por ejemplo, es posible programar el modelo directamente en su código para controlar lo que puede y no puede hacer, y a qué información tiene acceso, pero también se pueden aprovechar herramientas adicionales, como los GPTs de OpenAI o su símil, Copilot, en Microsoft. Percepción y uso de la IA en el trabajo: para el 41% de los argentinos, sus empleadores están atrasados en su adopción en Xataka', 'score': 0.99856746, 'raw_content': None}, {'title': 'Sí, las empresas ya están usando ChatGPT para atender a sus clientes ...', 'url': 'https://www.forbes.com.ec/innovacion/si-empresas-ya-estan-usando-chatgpt-atender-sus-clientes-n27791', 'content': 'Meta, Canva y Shopify, entre otras empresas, ya están utilizando la tecnología que sustenta a ChatGPT en sus chatbots de atención al cliente. 9 Enero de 2023 11.05. Desde el procesamiento de la devolución de un pedido en Shopify hasta el restablecimiento de una contraseña para una cuenta de Canva, es probable que el chatbot con el que', 'score': 0.9982993, 'raw_content': None}, {'title': 'Uso de ChatGPT en los bancos y otras entidades financieras', 'url': 'https://www.juancmejia.com/transformacion-digital/uso-de-chatgpt-en-los-bancos-y-otras-entidades-financieras/', 'content': 'Luego, el modelo puede ayudar a los bancos a recopilar datos del cliente, analizar la solvencia crediticia y proporcionar comentarios en tiempo real sobre las solicitudes de préstamos. ChatGPT puede ayudar a los bancos a proporcionar servicios personalizados de gestión de patrimonio a sus clientes mediante el análisis de datos del cliente y proporcionando recomendaciones de inversión personalizadas basadas en sus objetivos financieros individuales y tolerancia al riesgo. Desarrollo de un asistente virtual con ChatGPT que pueda interactuar con los clientes las 24 horas del día, los 7 días de la semana para realizar tareas como la gestión de cuentas, el pago de facturas y la ejecución de transacciones.', 'score': 0.9980276, 'raw_content': None}, {'title': 'ChatGPT: qué es y cómo puede transformar las soluciones financieras', 'url': 'https://blog.cobistopaz.com/es/blog/como-el-chatgpt-puede-transformar-las-soluciones-financieras', 'content': 'En relación con los servicios bancarios y financieros, ChatGPT ha demostrado ser una herramienta útil que ayuda a optimizar los procesos, mejorar el servicio al cliente y la toma de decisiones. Leer más May 14, 2020 La nube como elemento clave para la agilidad de la banca Contar con una infraestructura en la nube para la prestación de servicios financieros digitales es un factor diferenciador en cuanto a la agilidad del servicio y por esto es también una estrategia clave para la transformación digital de las entidades financieras. Actualmente, la tecnología está cambiando las reglas de juego y el usuario final tiene expectativas más altas con respecto a la diversificación de los servicios que su banco puede ofrecerle y en esto el Open banking se vuelve fundamental.', 'score': 0.9976769, 'raw_content': None}, {'title': '6 usos de ChatGPT para servicio al cliente - InvGate', 'url': 'https://blog.invgate.com/es/chatgpt-para-servicio-al-cliente', 'content': 'Ya vimos cómo ChatGPT puede ser una herramienta para el soporte IT y ahora vamos a descubrir cómo utilizar ChatGPT para servicio al cliente. Esto es lo obtenido cuando le solicitamos a ChatGPT que escribiera una nota sobre \"El papel de la inteligencia artificial en la atención al cliente\". Son capaces de responder preguntas y solicitudes sencillas, liberando a las personas de la atención al cliente para que se ocupen de cuestiones más complejas. Aumento de la eficiencia: la IA automatiza tareas y procesos repetitivos, liberando tiempo para que los representantes de atención al cliente se centren en cuestiones más complejas. Las empresas que adoptan la IA en esa área están mejor posicionadas que sus competidores y cuentan con las condiciones adecuadas para optimizar la satisfacción del cliente.', 'score': 0.9975751, 'raw_content': None}, {'title': 'Qué es ChatGPT y qué puede y no puede hacer (a día de hoy) - BBVA', 'url': 'https://www.bbva.com/es/innovacion/que-es-chatgpt-y-que-puede-y-no-puede-hacer-a-dia-de-hoy/', 'content': 'El contenido que ofrece este sistema, sin embargo, a veces puede ser incorrecto y nunca se basa en una comprensión o inteligencia similar a la humana, explica Bern Elliot, vicepresidente analista de Gartner. Pero, si hay un campo en el que ChatGPT y las tecnologías similares pueden destacar, es en la generación de contenido. BBVA está sentando las bases para afrontar el gran reto que supone la aplicación de la inteligencia artificial (IA) generativa en los servicios financieros. Según los expertos consultados, al poder procesar grandes cantidades de texto y datos, pueden extraer información valiosa para la toma de decisiones, analizando tendencias y opiniones sobre las empresas y el sector.', 'score': 0.994089, 'raw_content': None}, {'title': 'Los 10 usos que ChatGPT ofrece al sector bancario - elEconomista.es', 'url': 'https://www.eleconomista.es/banca-finanzas/noticias/12182807/03/23/Los-10-usos-que-ChatGPT-ofrece-al-sector-bancario-.html', 'content': 'Forbes ha recogido 10 posibles usos que se le podría dar a este sistema: 1. Servicio al consumidor. A través de chatbots, los bancos pueden ofrecer soporte las 24 horas. Una herramienta que ya', 'score': 0.9905509, 'raw_content': None}, {'title': 'Cómo pueden las empresas aplicar ChatGPT a sus negocios - BBVA', 'url': 'https://www.bbva.com/es/innovacion/como-pueden-las-empresas-aplicar-chatgpt-a-sus-negocios/', 'content': \"Cómo pueden las empresas aplicar ChatGPT a sus negocios. Los 'chatbots' llevan años automatizando tareas cotidianas de atención al cliente, reduciendo tanto la carga de trabajo del personal como los tiempos y costes empresariales. La irrupción de ChatGPT amplía el horizonte de aplicación de esta tecnología y su potencial para\", 'score': 0.9884919, 'raw_content': None}], 'response_time': 2.1}\n",
      "Consultando en Wikipedia: ¿Qué son los modelos de lenguaje en inteligencia artificial?\n",
=======
>>>>>>> Stashed changes
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLo siento, no tengo acceso a información en tiempo real, incluyendo datos sobre qué bancos están usando ChatGPT para atención al cliente.  Mi conocimiento se basa en la información con la que fui entrenado, y esa información no siempre está actualizada.  Para obtener información precisa y actualizada sobre este tema, te recomiendo buscar noticias financieras recientes o consultar directamente con los bancos que te interesen.\n",
      "\u001b[0m\n",
      "\n",
<<<<<<< Updated upstream
      "Pregunta: ¿Cómo se utiliza la IA en la agricultura?\n",
      "Respuesta (tavily):\n",
      "{'query': '¿Cómo se utiliza la IA en la agricultura?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Inteligencia artificial: ¿cómo podría transformar la agricultura?', 'url': 'https://alliancebioversityciat.org/es/stories/inteligencia-artificial-como-podria-transformar-agricultura', 'content': 'Tres proyectos en curso de la Alianza que recurren a la IA son\\xa0Tumaini (una aplicación para teléfonos inteligentes que permite a los cultivadores de banano resolver el 90% de las principales enfermedades y plagas),\\xa0Melisa (un chatbot que calcula el rendimiento del maíz y el trigo de los agricultores colombianos basándose en predicciones meteorológicas a largo plazo, variedades de suelo y cultivo, y fechas de siembra), y Artemis (sistemas tecnológicos de visión por ordenador que permiten a los mejoradores de cultivos desarrollar variedades adaptadas localmente y resilientes al clima). Además de la supervisión de cultivos y los servicios de asesoramiento, otro ejemplo prometedor de IA en la agricultura es la instalación de sensores subterráneos de humedad del suelo que podrían permitir a los agricultores estimar las necesidades de riego, ayudándoles así a utilizar los recursos de forma eficiente.', 'score': 0.99957615, 'raw_content': None}, {'title': '¿Cómo se utiliza la IA en la agricultura sostenible? | 2024', 'url': 'https://masterinteligenciaartificial.com/ia-en-la-agricultura-sostenible/', 'content': 'La IA impulsa los objetivos de desarrollo sostenible. Algunas de las principales áreas en las que se utiliza la IA en la agricultura sostenible son: La agricultura de precisión, que utiliza la IA para predecir el rendimiento de los cultivos mediante imágenes por satélite. La agricultura inteligente, que utiliza tecnología avanzada como', 'score': 0.99956435, 'raw_content': None}, {'title': 'Cómo la IA puede ayudar en la agricultura: cinco aplicaciones y casos ...', 'url': 'https://ichi.pro/es/como-la-ia-puede-ayudar-en-la-agricultura-cinco-aplicaciones-y-casos-de-uso-264553841764041', 'content': 'Las aplicaciones de la IA en la agricultura se expandieron para realizar una agricultura precisa y controlada al proporcionar una orientación adecuada a los agricultores sobre la siembra óptima, el manejo del agua, la rotación de cultivos, la cosecha oportuna, el manejo de nutrientes y los ataques de plagas. Las empresas involucradas en mejorar el aprendizaje automático o los productos o servicios basados \\u200b\\u200ben inteligencia artificial, como los datos de capacitación para la agricultura , los drones y la fabricación de máquinas automatizadas, obtendrán avances tecnológicos en el futuro, proporcionarán las aplicaciones más útiles para este sector, ayudando al mundo a lidiar con los problemas de producción de alimentos para el población creciente.', 'score': 0.9993148, 'raw_content': None}, {'title': 'Inteligencia Artificial en la agricultura, ¿es real? - Alsi', 'url': 'https://alsimaquinaria.com/inteligencia-artificial-en-la-agricultura/', 'content': 'Por último, la agricultura de precisión se beneficia de la IA al utilizar drones, sensores y sistemas de información geográfica para obtener información detallada sobre la salud de los cultivos, la calidad del suelo y otros factores relevantes para la toma de decisiones. Cómo implementar la Inteligencia Artificial en empresas hortofrutícolas', 'score': 0.9993148, 'raw_content': None}, {'title': 'Cómo se aplica la IA en la agricultura y algunos ejemplos', 'url': 'https://www.portalfruticola.com/noticias/2024/05/27/como-se-aplica-la-ia-en-la-agricultura-y-algunos-ejemplos/', 'content': 'La inteligencia artificial (IA) ha emergido como una de las tecnologías más transformadoras en la agricultura moderna, ofreciendo soluciones innovadoras para mejorar la eficiencia, productividad y sostenibilidad del sector agrícola. Estos sistemas utilizan sensores de humedad del suelo y datos climáticos para optimizar el uso del agua, lo que es especialmente crucial en regiones afectadas por la escasez de agua. AgroSmart es una startup brasileña que ofrece soluciones basadas en la IA para el monitoreo de cultivos y la gestión del agua. Al optimizar el uso de insumos y reducir las pérdidas por plagas y enfermedades, la IA puede ayudar a reducir los costos operativos para los agricultores.', 'score': 0.9989556, 'raw_content': None}, {'title': 'Cómo se aplica la IA en la agricultura y algunos ejemplos', 'url': 'https://www.cafi.org.ar/como-se-aplica-la-ia-en-la-agricultura-y-algunos-ejemplos/', 'content': 'La inteligencia artificial (IA) ha emergido como una de las tecnologías más transformadoras en la agricultura moderna, ofreciendo soluciones innovadoras para mejorar la eficiencia, productividad y sostenibilidad del sector agrícola. AgroSmart es una startup brasileña que ofrece soluciones basadas en la IA para el monitoreo de cultivos y la gestión del agua. Al optimizar el uso de insumos y reducir las pérdidas por plagas y enfermedades, la IA puede ayudar a reducir los costos operativos para los agricultores. La IA proporciona a los agricultores datos y análisis detallados, permitiéndoles tomar decisiones informadas y basadas en evidencia, mejorando la gestión general de las explotaciones agrícolas. La IA está presente en el monitoreo de cultivos y el análisis del suelo hasta la gestión de plagas y el riego inteligente.', 'score': 0.99893504, 'raw_content': None}, {'title': 'El papel de la inteligencia artificial en la modernización del sector ...', 'url': 'https://mundoagropecuario.com/el-papel-de-la-inteligencia-artificial-en-la-modernizacion-del-sector-agropecuario/', 'content': 'En este artículo, exploraremos cómo la inteligencia artificial está modernizando el sector agropecuario, y cómo estas innovaciones están beneficiando tanto a los agricultores como a la sociedad en general. Los agricultores pueden obtener información sobre el estado del suelo, el nivel de humedad, la presencia de plagas y enfermedades, y otros factores cruciales para la producción. Los algoritmos pueden ajustar automáticamente las raciones de alimentos en función de las necesidades individuales de cada animal, lo que mejora la eficiencia de la alimentación y el bienestar del ganado. Al mismo tiempo, la IA está fomentando prácticas agrícolas más sostenibles y respetuosas con el medio ambiente, ayudando a enfrentar los desafíos que enfrenta la agricultura en el siglo XXI.', 'score': 0.9982109, 'raw_content': None}, {'title': 'La Inteligencia artificial en el sector agrícola', 'url': 'https://inteligenciaartificialpro.com/blog/inteligencia-artificial-en-el-sector-agricola/', 'content': 'Mejora de la calidad de los productos. La inteligencia artificial (IA) se ha convertido en una herramienta eficaz para aprovechar al máximo el complejo ecosistema de la agricultura.Desde optimizar los cultivos hasta mejorar la producción y controlar el rendimiento de los diferentes productos, la IA es cada vez más valiosa. La aplicación de la IA en el sector agrícola permite a los', 'score': 0.9973477, 'raw_content': None}, {'title': 'Cinco aplicaciones de la inteligencia artificial en agricultura', 'url': 'https://www.plataformatierra.es/innovacion/IA-inteligencia-artificial-aplicaciones', 'content': 'La expansión de las nuevas categorías de inteligencia artificial ha permitido expandir las funcionalidades de los sistemas de detección por modelos capaces diagnosticar, a partir de una fotografía, el cuadro del síntomas del vegetal, junto con las alternativas disponibles para su control. Con ello, se dota a los agentes de instrumentos útiles para poder aplicar una agricultura basada en el conocimiento y la eficiencia. Por ello, tiene una importancia capital efectuar un análisis económico para determinar la viabilidad de la operación, el cual debe combinarse con un análisis de necesidades ante la oferta diversa de productos y servicios tecnológicos que existe, seleccionando aquellos equipos que más se adapten a las necesidades de los productores.', 'score': 0.9947187, 'raw_content': None}, {'title': 'INTELIGENCIA ARTIFICIAL EN LA AGRICULTURA - Universidad Agrícola', 'url': 'https://universidadagricola.com/inteligencia-artificial-en-la-agricultura/', 'content': 'La RAE (Real Academia Española) define la Inteligencia Artificial (IA) como la \"disciplina científica que se ocupa de crear programas informáticos que ejecutan operaciones comparables a las que realiza la mente humana, como el aprendizaje o el razonamiento lógico\". Según la FAO (Organización de las Naciones Unidas para la Agricultura', 'score': 0.9921537, 'raw_content': None}], 'response_time': 2.65}\n",
      "Consultando en Wikipedia: ¿Quién es Alan Turing y cuál fue su contribución a la IA?\n",
=======
      "\u001b[1m> Finished chain.\u001b[0m\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to find information about which banks are using ChatGPT or similar AI for customer service.  I'll use the search engine to find relevant articles and news reports.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"¿Qué bancos están usando ChatGPT para atención al cliente?\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.eleconomista.com.mx/los-especiales/Futuro-digital-El-rol-de-ChatGPT-en-el-servicio-al-cliente-20240508-0019.html', 'content': 'Como parte de su proceso constante de innovación, Santander México incorporó desde 2023 la Inteligencia Artificial Generativa a su bot de atención a clientes en Facebook conectando ChatGPT para personalizar las respuestas a los clientes, siendo la primera institución financiera con esta innovación en México, así lo comentó Paola Herrera Dávila, directora de Engagement Center de Santander México en entrevista con El Economista. En el caso de la atención a clientes en redes sociales, “que es donde hemos implementado un bot con ChatGPT, lo entrenamos para atender originalmente en 25 categorías diferentes que son las que más recurrentemente preguntan los clientes, por ejemplo, dudas sobre tarjetas, estados de cuenta, servicios, etcétera”, dijo Herrera.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The search results show that Santander México is using ChatGPT for customer service on Facebook.  I need to see if there are other banks mentioned in other search results.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"banks using ChatGPT customer service\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.analyticsinsight.net/artificial-intelligence/10-use-cases-of-chatgpt-applications-in-the-banking-sector', 'content': \"The following are a few of the use cases of ChatGPT in banks: 1. Client assistance: The banking sector can utilize ChatGPT to change their client care by offering ongoing help using a chatbot. It can respond quickly and effectively to customer inquiries, complaints, and requests for information thanks to ChatGPT's natural language processing\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The second search provides general information about ChatGPT's use in banking customer service but doesn't name specific banks beyond the one already identified.  I'll refine my search to focus on specific examples.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"banks using AI chatbots customer service examples\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://builtin.com/artificial-intelligence/ai-in-banking', 'content': 'Location: McLean, Virginia. Capital One is another example of a bank embracing the use of AI to better serve its customers. In 2017, the bank released Eno, a virtual assistant that users can communicate with through a mobile app, text, email and on a desktop. Eno lets users text questions, receive fraud alerts and takes care of tasks like'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: This last search result mentions Capital One using an AI chatbot, Eno, but not specifically ChatGPT.  The initial search definitively identified Santander Mexico as using ChatGPT.  I don't have enough information to definitively list other banks using ChatGPT specifically.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "\n",
      "Final Answer: Based on the available information, Santander México is confirmed to be using ChatGPT for customer service on Facebook.  While other banks utilize AI chatbots for customer service,  the provided searches did not confirm the use of ChatGPT specifically by any other bank.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '¿Qué bancos están usando ChatGPT para atención al cliente?', 'output': 'Lo siento, no tengo acceso a información en tiempo real, incluyendo datos sobre qué bancos están usando ChatGPT para atención al cliente.  Mi conocimiento se basa en la información con la que fui entrenado, y esa información no siempre está actualizada.  Para obtener información precisa y actualizada sobre este tema, te recomiendo buscar noticias financieras recientes o consultar directamente con los bancos que te interesen.\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'x': 'modelos de lenguaje en inteligencia artificial'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\u001b[32;1m\u001b[1;3mLo siento, no pude encontrar información sobre \"modelos de lenguaje en inteligencia artificial\" en Wikipedia.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to find a definition of language models in artificial intelligence.  A search engine will be helpful for this.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"language models in artificial intelligence\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.autonomous.ai/ourblog/ai-language-models', 'content': '1. What is an AI Language Model? An AI language model is a type of artificial intelligence designed to understand, generate, and process human language. 1. Are large language models generative AI? 3. How can you make an AI language model? 9. Which AI language model is used for text-to-image generation? Are large language models the same as generative AI? While generative AI encompasses any AI that can create new data (like images, music, or text), large language models specifically focus on generating and processing human language. Whether you’re generating creative content or analyzing complex data, the best AI language models of 2024 offer powerful solutions to enhance productivity and innovation across industries.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observation provides a good definition. I can formulate an answer based on this.\n",
      "\n",
      "Thought: I now know the final answer.\n",
      "Final Answer: Los modelos de lenguaje en inteligencia artificial son un tipo de inteligencia artificial diseñados para comprender, generar y procesar el lenguaje humano.  Se enfocan en generar y procesar lenguaje humano, ya sea para crear contenido creativo o analizar datos complejos.  Aunque la IA generativa abarca cualquier IA que pueda crear nuevos datos (como imágenes, música o texto), los modelos de lenguaje grandes se centran específicamente en el lenguaje humano.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '¿Qué son los modelos de lenguaje en inteligencia artificial?', 'output': 'Lo siento, no pude encontrar información sobre \"modelos de lenguaje en inteligencia artificial\" en Wikipedia.\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'x': 'Uso de la IA en la agricultura'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Ethanol fuel in Brazil\n",
      "Summary: Brazil is the world's second largest producer of ethanol fuel.\u001b[0m\u001b[32;1m\u001b[1;3mLo siento, pero la información que obtuve de Wikipedia sobre el \"Uso de la IA en la agricultura\" no es relevante para tu pregunta.  Necesito más información o una fuente diferente para poder responder adecuadamente.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question about the use of AI in agriculture, I need to search for information on this topic in Spanish.  I will use the tavily_search_results_json tool to find relevant and reliable information.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"aplicaciones de la inteligencia artificial en la agricultura\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://ichi.pro/es/como-la-ia-puede-ayudar-en-la-agricultura-cinco-aplicaciones-y-casos-de-uso-264553841764041', 'content': 'Las aplicaciones de la IA en la agricultura se expandieron para realizar una agricultura precisa y controlada al proporcionar una orientación adecuada a los agricultores sobre la siembra óptima, el manejo del agua, la rotación de cultivos, la cosecha oportuna, el manejo de nutrientes y los ataques de plagas. Las empresas involucradas en mejorar el aprendizaje automático o los productos o servicios basados \\u200b\\u200ben inteligencia artificial, como los datos de capacitación para la agricultura , los drones y la fabricación de máquinas automatizadas, obtendrán avances tecnológicos en el futuro, proporcionarán las aplicaciones más útiles para este sector, ayudando al mundo a lidiar con los problemas de producción de alimentos para el población creciente.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observation provides a good overview, but I need more detail. I'll refine my search query to get more specific examples.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"ejemplos de inteligencia artificial en agricultura\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://eos.com/es/blog/agricultura-inteligente/', 'content': 'Algunos ejemplos de inteligencia artificial en la agricultura eficaces y sencillos de usar son los siguientes: Aprendizaje automático. La tecnología de aprendizaje automático le permiten predecir cambios en el clima, los parámetros del suelo y el agua, el contenido de carbono, la propagación de enfermedades y plagas, etc.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observations provide some examples but lack a comprehensive overview. I will broaden the search to encompass various AI applications in agriculture.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"usos de la inteligencia artificial en la agricultura ejemplos\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.cafi.org.ar/como-se-aplica-la-ia-en-la-agricultura-y-algunos-ejemplos/', 'content': 'La inteligencia artificial (IA) ha emergido como una de las tecnologías más transformadoras en la agricultura moderna, ofreciendo soluciones innovadoras para mejorar la eficiencia, productividad y sostenibilidad del sector agrícola. AgroSmart es una startup brasileña que ofrece soluciones basadas en la IA para el monitoreo de cultivos y la gestión del agua. Al optimizar el uso de insumos y reducir las pérdidas por plagas y enfermedades, la IA puede ayudar a reducir los costos operativos para los agricultores. La IA proporciona a los agricultores datos y análisis detallados, permitiéndoles tomar decisiones informadas y basadas en evidencia, mejorando la gestión general de las explotaciones agrícolas. La IA está presente en el monitoreo de cultivos y el análisis del suelo hasta la gestión de plagas y el riego inteligente.'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now have several examples and a general overview from the different searches. I can synthesize this information into a comprehensive answer.\n",
      "\n",
      "Final Answer: La inteligencia artificial (IA) se utiliza en la agricultura de diversas maneras para mejorar la eficiencia, productividad y sostenibilidad.  Algunos ejemplos incluyen: el aprendizaje automático para predecir cambios climáticos, parámetros del suelo y agua, propagación de enfermedades y plagas; el monitoreo de cultivos y análisis del suelo; la gestión del agua y el riego inteligente; la optimización del uso de insumos (fertilizantes, pesticidas) para reducir costos y pérdidas; y la toma de decisiones informadas basadas en datos y análisis detallados.  Empresas como AgroSmart utilizan IA para ofrecer soluciones de monitoreo de cultivos y gestión del agua. En resumen, la IA ayuda a los agricultores a realizar una agricultura precisa y controlada, mejorando la gestión general de sus explotaciones.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '¿Cómo se utiliza la IA en la agricultura?', 'output': 'Lo siento, pero la información que obtuve de Wikipedia sobre el \"Uso de la IA en la agricultura\" no es relevante para tu pregunta.  Necesito más información o una fuente diferente para poder responder adecuadamente.\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'x': 'Alan Turing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Alan Turing\n",
      "Summary: Alan Mathison Turing  (; 23 June 1912 – 7 June 1954) was an English mathe\u001b[0m\u001b[32;1m\u001b[1;3mAlan Mathison Turing (23 de junio de 1912 – 7 de junio de 1954) fue un matemático, lógico, informático teórico, criptógrafo, filósofo y biólogo matemático británico.  Considerado uno de los padres de la ciencia de la computación y la inteligencia artificial, su contribución más relevante a la IA fue el desarrollo del Test de Turing, una prueba para determinar si una máquina puede exhibir un comportamiento inteligente equivalente al de un humano.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to find information about Alan Turing and his contributions to Artificial Intelligence.  A search engine will be the best tool for this.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Alan Turing contributions to AI\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.nist.gov/blogs/taking-measure/alan-turings-everlasting-contributions-computing-ai-and-cryptography', 'content': 'Turing went on to make fundamental contributions to AI, theoretical biology and cryptography. His involvement with this last subject brought him honor and fame during World War II, when he played a very important role in adapting and extending cryptanalytic techniques invented by Polish mathematicians. This work broke the German Enigma machine'}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observation provides a starting point but lacks detail on his specific contributions to AI. I need to refine my search to get more specific information about his AI contributions.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"Alan Turing's specific contributions to artificial intelligence\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://aimagazine.com/machine-learning/alan-turing-a-strong-legacy-that-powers-modern-ai', 'content': \"Alan Turing was a remarkable man, with his commitments to science and technology arguably shaping the modern artificial intelligence (AI) landscape as we know it. Today, 7th June 2024, marks 70 years since Alan Turing's death in 1954. An outstanding British mathematician and foundational figure in computer science and AI, Turing was\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: The observations provide links to articles that discuss Alan Turing's contributions to AI, but I need to access the content of those articles to get a comprehensive answer.  Since I don't have the ability to access external websites, I will summarize the information I have gathered so far.\n",
      "\n",
      "Thought: I now know the final answer.\n",
      "\n",
      "Final Answer: Alan Turing is considered a foundational figure in computer science and artificial intelligence.  While the provided search results don't give specific details of his contributions, they highlight his significant and lasting impact on the field of AI.  Further research into the linked articles would provide more specific details.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '¿Quién es Alan Turing y cuál fue su contribución a la IA?', 'output': 'Alan Mathison Turing (23 de junio de 1912 – 7 de junio de 1954) fue un matemático, lógico, informático teórico, criptógrafo, filósofo y biólogo matemático británico.  Considerado uno de los padres de la ciencia de la computación y la inteligencia artificial, su contribución más relevante a la IA fue el desarrollo del Test de Turing, una prueba para determinar si una máquina puede exhibir un comportamiento inteligente equivalente al de un humano.\\n'}\n"
     ]
    }
   ],
   "source": [
    "preguntas = [\n",
    "\"¿Qué bancos están usando ChatGPT para atención al cliente?\",\n",
    "\"¿Qué son los modelos de lenguaje en inteligencia artificial?\",\n",
    "\"¿Cómo se utiliza la IA en la agricultura?\",\n",
    "\"¿Quién es Alan Turing y cuál fue su contribución a la IA?\"\n",
    "]\n",
    "\n",
    "# Iterar sobre las preguntas y obtener respuestas\n",
    "for consulta in preguntas:\n",
    "    respuesta = wiki_agent.invoke({\"input\": consulta})\n",
    "    respuesta2 = agent_executor.invoke({\"input\": consulta})\n",
    "    print(respuesta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El agente selecciona correctamente la herramienta según la naturaleza de la consulta:\n",
    "\n",
    "Tavily: Para temas prácticos, actuales y con necesidad de información variada y reciente.\n",
    "Wikipedia: Para definiciones teóricas, históricas y académicas.\n",
    "Casos específicos de uso:\n",
    "\n",
    "Use Tavily para preguntas como \"¿Qué empresas usan IA para [x]?\" o \"¿Cómo se aplica la IA en [sector]?\".\n",
    "Use Wikipedia para definiciones, biografías, o historia como \"¿Qué es IA débil?\" o \"¿Qué aportó Alan Turing a la IA?\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZbDTYiogquv"
   },
   "source": [
    "### **2.3 Multi Agente (1.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
    "\" width=\"450\">\n",
    "</p>\n",
    "\n",
    "El objetivo de esta subsección es encapsular las funcionalidades creadas en una solución multiagente con un **supervisor**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-iUfH0WvI6m"
   },
   "source": [
    "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
    "\n",
    "Transforme la solución RAG de la sección 2.1 y el agente de la sección 2.2 a *tools* (una tool por cada uno)."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 26,
   "metadata": {
    "id": "pw1cfTtvv1AZ"
   },
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "Field 'description' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/model-field-overridden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTool\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mRAGTool\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseTool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Tool para el sistema RAG basado en los documentos cargados.\"\"\"\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResponde preguntas basadas en los documentos cargados y vectorizados en la solución RAG.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:115\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m config_wrapper \u001b[38;5;241m=\u001b[39m ConfigWrapper\u001b[38;5;241m.\u001b[39mfor_model(bases, namespace, kwargs)\n\u001b[0;32m    114\u001b[0m namespace[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m config_wrapper\u001b[38;5;241m.\u001b[39mconfig_dict\n\u001b[1;32m--> 115\u001b[0m private_attributes \u001b[38;5;241m=\u001b[39m \u001b[43minspect_namespace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignored_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_field_names\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m private_attributes \u001b[38;5;129;01mor\u001b[39;00m base_private_attributes:\n\u001b[0;32m    119\u001b[0m     original_model_post_init \u001b[38;5;241m=\u001b[39m get_model_post_init(namespace, bases)\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:418\u001b[0m, in \u001b[0;36minspect_namespace\u001b[1;34m(namespace, ignored_types, base_class_vars, base_class_fields)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m raw_annotations:\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01min\u001b[39;00m base_class_fields:\n\u001b[1;32m--> 418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m    419\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m defined on a base class was overridden by a non-annotated attribute. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    420\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll field definitions, including overrides, require a type annotation.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    421\u001b[0m             code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-field-overridden\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    422\u001b[0m         )\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, FieldInfo):\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m    425\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m requires a type annotation\u001b[39m\u001b[38;5;124m'\u001b[39m, code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-field-missing-annotation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    426\u001b[0m         )\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: Field 'description' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/model-field-overridden"
     ]
    }
   ],
   "source": [
    "from langchain.tools import BaseTool\n",
    "\n",
    "class RAGTool(BaseTool):\n",
    "    \"\"\"Tool para el sistema RAG basado en los documentos cargados.\"\"\"\n",
    "    description = \"Responde preguntas basadas en los documentos cargados y vectorizados en la solución RAG.\"\n",
    "\n",
    "    def __init__(self, retriever_chain):\n",
    "        self.retriever_chain = retriever_chain\n",
    "\n",
    "    def _run(self, query: str):\n",
    "        \"\"\"Ejecuta el RAG y devuelve una respuesta.\"\"\"\n",
    "        try:\n",
    "            return self.retriever_chain.invoke(query)\n",
    "        except Exception as e:\n",
    "            return f\"Error en la herramienta RAG: {e}\"\n",
    "\n",
    "    async def _arun(self, query: str):\n",
    "        \"\"\"Versión asincrónica (por si se necesita más adelante).\"\"\"\n",
    "        raise NotImplementedError(\"RAGTool no soporta ejecución asincrónica.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "Field 'name' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/model-field-overridden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mMultiSearchTool\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseTool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Tool para realizar búsquedas en Tavily o Wikipedia.\"\"\"\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulti_search_tool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:115\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m config_wrapper \u001b[38;5;241m=\u001b[39m ConfigWrapper\u001b[38;5;241m.\u001b[39mfor_model(bases, namespace, kwargs)\n\u001b[0;32m    114\u001b[0m namespace[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m config_wrapper\u001b[38;5;241m.\u001b[39mconfig_dict\n\u001b[1;32m--> 115\u001b[0m private_attributes \u001b[38;5;241m=\u001b[39m \u001b[43minspect_namespace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignored_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_field_names\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m private_attributes \u001b[38;5;129;01mor\u001b[39;00m base_private_attributes:\n\u001b[0;32m    119\u001b[0m     original_model_post_init \u001b[38;5;241m=\u001b[39m get_model_post_init(namespace, bases)\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_model_construction.py:418\u001b[0m, in \u001b[0;36minspect_namespace\u001b[1;34m(namespace, ignored_types, base_class_vars, base_class_fields)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m raw_annotations:\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01min\u001b[39;00m base_class_fields:\n\u001b[1;32m--> 418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m    419\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m defined on a base class was overridden by a non-annotated attribute. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    420\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll field definitions, including overrides, require a type annotation.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    421\u001b[0m             code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-field-overridden\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    422\u001b[0m         )\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, FieldInfo):\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m    425\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m requires a type annotation\u001b[39m\u001b[38;5;124m'\u001b[39m, code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-field-missing-annotation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    426\u001b[0m         )\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: Field 'name' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/model-field-overridden"
     ]
    }
   ],
   "source": [
    "class MultiSearchTool(BaseTool):\n",
    "    \"\"\"Tool para realizar búsquedas en Tavily o Wikipedia.\"\"\"\n",
    "    name = \"multi_search_tool\"\n",
    "    description = \"Busca información usando Tavily o Wikipedia según la naturaleza de la consulta.\"\n",
    "\n",
    "    def __init__(self, tavily_tool, wikipedia_tool):\n",
    "        self.tavily_tool = tavily_tool\n",
    "        self.wikipedia_tool = wikipedia_tool\n",
    "\n",
    "    def _run(self, query: dict):\n",
    "        \"\"\"Ejecuta la búsqueda según la fuente especificada.\"\"\"\n",
    "        pregunta = query.get(\"pregunta\")\n",
    "        fuente = query.get(\"fuente\", \"tavily\")\n",
    "        if not pregunta:\n",
    "            return \"Error: La pregunta es requerida.\"\n",
    "        \n",
    "        try:\n",
    "            if fuente == \"tavily\":\n",
    "                return self.tavily_tool.search(pregunta)\n",
    "            elif fuente == \"wikipedia\":\n",
    "                return self.wikipedia_tool.search(pregunta)\n",
    "            else:\n",
    "                return \"Error: Fuente no reconocida. Use 'tavily' o 'wikipedia'.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error en MultiSearchTool: {e}\"\n",
    "\n",
    "    async def _arun(self, query: dict):\n",
    "        \"\"\"Versión asincrónica.\"\"\"\n",
    "        raise NotImplementedError(\"MultiSearchTool no soporta ejecución asincrónica.\")\n"
=======
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def wikipedia_agent(consulta: str) -> str:\n",
    "    \"\"\"Consulta en wikipedia.\"\"\"\n",
    "    respuesta = wiki_agent.invoke({\"input\": consulta})\n",
    "    return respuesta\n",
    "@tool\n",
    "def Tavily_agent(consulta: str) -> str:\n",
    "    \"\"\"Consulta en Tavily.\"\"\"\n",
    "    respuesta= agent_executor.invoke({\"input\": consulta})\n",
    "    return respuesta\n",
    "def constitucion(consulta: str) -> str:\n",
    "    \"\"\"Consulta en la constitucion de 1925.\"\"\"\n",
    "    respuesta = rag_chain1.invoke(consulta)\n",
    "    return respuesta\n",
    "def series(consulta: str) -> str:\n",
    "    \"\"\"Consulta de series temporales.\"\"\"\n",
    "    respuesta = rag_chain2.invoke(consulta)\n",
    "    return respuesta\n",
    "\n",
    "tools = [wikipedia_agent,Tavily_agent,constitucion,series]"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQYNjT_0vPCg"
   },
   "source": [
    "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
    "\n",
    "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 28,
   "metadata": {
    "id": "yv2ZY0BAv1RD"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RAGTool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Definir tools\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m rag_tool \u001b[38;5;241m=\u001b[39m \u001b[43mRAGTool\u001b[49m(retriever_chain\u001b[38;5;241m=\u001b[39mrag_chain1)  \u001b[38;5;66;03m# Usamos la RAG creada previamente\u001b[39;00m\n\u001b[0;32m      7\u001b[0m multi_search_tool \u001b[38;5;241m=\u001b[39m MultiSearchTool(tavily_tool\u001b[38;5;241m=\u001b[39mtavily_tool, wikipedia_tool\u001b[38;5;241m=\u001b[39mwikipedia_tool)\n\u001b[0;32m      9\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     Tool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAGTool\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mrag_tool\u001b[38;5;241m.\u001b[39m_run, description\u001b[38;5;241m=\u001b[39mrag_tool\u001b[38;5;241m.\u001b[39mdescription),\n\u001b[0;32m     11\u001b[0m     Tool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiSearchTool\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m=\u001b[39mmulti_search_tool\u001b[38;5;241m.\u001b[39m_run, description\u001b[38;5;241m=\u001b[39mmulti_search_tool\u001b[38;5;241m.\u001b[39mdescription)\n\u001b[0;32m     12\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RAGTool' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Definir tools\n",
    "rag_tool = RAGTool(retriever_chain=rag_chain1)  # Usamos la RAG creada previamente\n",
    "multi_search_tool = MultiSearchTool(tavily_tool=tavily_tool, wikipedia_tool=wikipedia_tool)\n",
    "\n",
    "tools = [\n",
    "    Tool(name=\"RAGTool\", func=rag_tool._run, description=rag_tool.description),\n",
    "    Tool(name=\"MultiSearchTool\", func=multi_search_tool._run, description=multi_search_tool.description)\n",
    "]\n",
    "\n",
    "# Prompt del agente supervisor\n",
    "supervisor_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Eres un agente supervisor que tiene acceso a varias herramientas:\n",
    "1. RAGTool para responder preguntas basadas en documentos cargados.\n",
    "2. MultiSearchTool para buscar en Tavily o Wikipedia.\n",
    "\n",
    "Para cada consulta, selecciona la herramienta adecuada y proporciona una respuesta clara y concisa.\n",
    "\n",
    "Pregunta: {input}\n",
    "\"\"\")\n",
    "\n",
    "# Inicializar el agente supervisor\n",
    "supervisor = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    prompt=supervisor_prompt,\n",
    "    output_parser=StrOutputParser(),\n",
    ")\n"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noten como ahora se incluye la variable agent_scratchpad\n",
    "supervisor_template = \"\"\"\n",
    "Eres un experto en todo lo que se refiera a entregar informacion muy resumida desde wikipedia,\n",
    "series temporales, la constitucion de 1925 y sobre hacer busquedas en internet mediante Tavily.\n",
    "\n",
    "Pregunta: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(supervisor_template)\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea3zWlvyvY7K"
   },
   "source": [
    "#### **2.3.3 Verificación de respuestas (0.25 puntos)**\n",
    "\n",
    "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. ¿Cómo varían las respuestas bajo este enfoque?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 29,
=======
   "execution_count": 46,
>>>>>>> Stashed changes
   "metadata": {
    "id": "6_1t0zkgv1qW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "\n",
      "----------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'supervisor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     respuesta \u001b[38;5;241m=\u001b[39m supervisor\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: pregunta})\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     respuesta \u001b[38;5;241m=\u001b[39m \u001b[43msupervisor\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: pregunta})\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPregunta: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpregunta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRespuesta: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrespuesta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'supervisor' is not defined"
=======
      "Consultando en Tavily: cómo puedo hacerme millonario?\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mroute_question\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcómo puedo hacerme millonario?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[45], line 15\u001b[0m, in \u001b[0;36mroute_question\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m     13\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m agente\u001b[38;5;241m.\u001b[39mresponder(question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikipedia\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43magente\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtavily\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries temporales/forecasting\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m topic:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rag_chain2\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: question})\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "preguntas = [\n",
    "    \"¿Cuáles son los principios fundamentales que establece la Constitución de 1925 en cuanto a la organización del Estado y la soberanía?\",  # RAG\n",
    "    \"¿Qué establece la Constitución de 1925 sobre la responsabilidad del Estado hacia la salud pública?\",  # RAG\n",
    "    \"¿Qué derechos de libre tránsito establece la Constitución de 1925?\",  # RAG\n",
    "    {\"pregunta\": \"¿Qué bancos están usando ChatGPT para atención al cliente?\", \"fuente\": \"tavily\"},  # MultiSearch\n",
    "    {\"pregunta\": \"¿Qué son los modelos de lenguaje en inteligencia artificial?\", \"fuente\": \"wikipedia\"},  # MultiSearch\n",
    "]\n",
    "\n",
    "# Ejecutar pruebas\n",
    "for pregunta in preguntas:\n",
    "    print(\"\\n----------------------------\")\n",
    "    if isinstance(pregunta, dict):\n",
    "        respuesta = supervisor.invoke({\"input\": pregunta})\n",
    "    else:\n",
    "        respuesta = supervisor.invoke({\"input\": pregunta})\n",
    "    print(f\"Pregunta: {pregunta}\\nRespuesta: {respuesta}\")\n"
=======
    "print(route_question(\"cómo puedo hacerme millonario?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mroute_question\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQue es el MAE en las series temporales?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[34], line 17\u001b[0m, in \u001b[0;36mroute_question\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m     15\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m agente\u001b[38;5;241m.\u001b[39mresponder(question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtavily\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries temporales/forecasting\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m topic:\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrag_chain2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# de lo contrario, redireccionar pregunta\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m redirect_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question})\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3727\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3722\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3723\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3724\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3725\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3726\u001b[0m         ]\n\u001b[1;32m-> 3727\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3728\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3711\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[1;34m(step, input, config, key)\u001b[0m\n\u001b[0;32m   3709\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   3710\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m-> 3711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3713\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_core\\retrievers.py:254\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    253\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    257\u001b[0m         result,\n\u001b[0;32m    258\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_core\\retrievers.py:247\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 247\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1080\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[0;32m   1078\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1080\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1082\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[0;32m   1084\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[0;32m   1085\u001b[0m             )\n\u001b[0;32m   1086\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:641\u001b[0m, in \u001b[0;36mFAISS.similarity_search\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    623\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    628\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    629\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:513\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    496\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m    497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[0;32m    515\u001b[0m         embedding,\n\u001b[0;32m    516\u001b[0m         k,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:265\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function, Embeddings):\n\u001b[1;32m--> 265\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function(text)\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:256\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_query\u001b[1;34m(self, text, task_type, title, output_dimensionality)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed a text.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    Embedding for the text.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    255\u001b[0m task_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETRIEVAL_QUERY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dimensionality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dimensionality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:207\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[1;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[0;32m    205\u001b[0m embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    206\u001b[0m batch_start_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mGoogleGenerativeAIEmbeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m titles:\n\u001b[0;32m    209\u001b[0m         titles_batch \u001b[38;5;241m=\u001b[39m titles[\n\u001b[0;32m    210\u001b[0m             batch_start_index : batch_start_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[0;32m    211\u001b[0m         ]\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:131\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings._prepare_batches\u001b[1;34m(texts, batch_size)\u001b[0m\n\u001b[0;32m    124\u001b[0m current_text \u001b[38;5;241m=\u001b[39m texts[text_index]\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Number of tokens per a text is conservatively estimated\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# as 2 times number of words, punctuation and whitespace characters.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Using `count_tokens` API will make batching too expensive.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Utilizing a tokenizer, would add a dependency that would not\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# necessarily be reused by the application using this class.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m current_text_token_cnt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[43mGoogleGenerativeAIEmbeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_by_punctuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    133\u001b[0m )\n\u001b[0;32m    134\u001b[0m end_of_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_text_token_cnt \u001b[38;5;241m>\u001b[39m _MAX_TOKENS_PER_BATCH:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Current text is too big even for a single batch.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Such request will fail, but we still make a batch\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# so that the app can get the error from the API.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:109\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings._split_by_punctuation\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    107\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m([\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_by\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Using re.split to split the text based on the pattern\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [segment \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m segment]\n",
      "File \u001b[1;32mc:\\Users\\vicen\\anaconda3\\Lib\\re\\__init__.py:207\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(pattern, string, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Split the source string by the occurrences of the pattern,\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    returning a list containing the resulting substrings.  If\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    capturing parentheses are used in pattern, then the text of all\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    and the remainder of the string is returned as the final element\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    of the list.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxsplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object, got 'dict'"
     ]
    }
   ],
   "source": [
    "print(route_question(\"Que es el MAE en las series temporales?\"))"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb8bdAmYvgwn"
   },
   "source": [
    "#### **2.3.4 Análisis (0.25 puntos)**\n",
    "\n",
    "¿Qué diferencias tiene este enfoque con la solución *Router* vista en clases? Nombre al menos una ventaja y desventaja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAUlJxqoLK5r"
   },
   "source": [
    "`escriba su respuesta acá`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JWVSuWiZ8Mj"
   },
   "source": [
    "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
    "\n",
    "- Pregunta 1: \"Hola! mi nombre es Sebastián\"\n",
    "  - Respuesta esperada: \"Hola Sebastián! ...\"\n",
    "- Pregunta 2: \"Cual es mi nombre?\"\n",
    "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
    "  - **Respuesta esperada: \"Tu nombre es Sebastián\"**\n",
    "\n",
    "Para solucionar esto, se les solicita agregar un componente de **memoria** a la solución entregada en el punto 2.3.\n",
    "\n",
    "**Nota: El Bonus es válido <u>sólo para la sección 2 de Large Language Models.</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6Y7tIPJLPfB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFc3jBT5g0kT"
   },
   "source": [
    "### **2.5 Despliegue (0 puntos)**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
    "\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a través de `gradio`, una librería especializada en el levantamiento rápido de demos basadas en ML.\n",
    "\n",
    "Primero instalamos la librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T8TsvnCPbkIA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cached-path 1.6.3 requires huggingface-hub<0.24.0,>=0.8.1, but you have huggingface-hub 0.26.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJBztEUovKsF"
   },
   "source": [
    "Luego sólo deben ejecutar el siguiente código e interactuar con la interfaz a través del notebook o del link generado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Z3KedQSvg1-n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1574, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 710, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 815, in asyncgen_wrapper\n",
      "    response = await iterator.__anext__()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\chat_interface.py\", line 678, in _stream_fn\n",
      "    first_response = await async_iteration(generator)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 710, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 704, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vicen\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 687, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\vicen\\AppData\\Local\\Temp\\ipykernel_2720\\4226380554.py\", line 12, in agent_response\n",
      "    assert type(response) == str, \"output de route_question debe ser string\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: output de route_question debe ser string\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def agent_response(message, history):\n",
    "  '''\n",
    "  Función para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
    "  '''\n",
    "  # get chatbot response\n",
    "  response = ... # rellenar con la respuesta de su chat\n",
    "\n",
    "  # assert\n",
    "  assert type(response) == str, \"output de route_question debe ser string\"\n",
    "\n",
    "  # \"streaming\" response\n",
    "  for i in range(len(response)):\n",
    "    time.sleep(0.015)\n",
    "    yield response[: i+1]\n",
    "\n",
    "gr.ChatInterface(\n",
    "    agent_response,\n",
    "    type=\"messages\",\n",
    "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
    "    description=\"Hola! Soy un chatbot muy útil :)\", # también la descripción\n",
    "    theme=\"soft\",\n",
    "    ).launch(\n",
    "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
    "        debug = False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
